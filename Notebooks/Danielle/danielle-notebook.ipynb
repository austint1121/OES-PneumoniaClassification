{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-11-16T18:23:06.667211Z","iopub.execute_input":"2021-11-16T18:23:06.668523Z","iopub.status.idle":"2021-11-16T18:23:19.964609Z","shell.execute_reply.started":"2021-11-16T18:23:06.668368Z","shell.execute_reply":"2021-11-16T18:23:19.963529Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import PIL \nimage = PIL.Image.open('/kaggle/input/chest-xray-pneumonia/chest_xray/train/NORMAL/IM-0219-0001.jpeg')","metadata":{"execution":{"iopub.status.busy":"2021-11-16T18:23:19.967700Z","iopub.execute_input":"2021-11-16T18:23:19.968077Z","iopub.status.idle":"2021-11-16T18:23:20.017052Z","shell.execute_reply.started":"2021-11-16T18:23:19.968029Z","shell.execute_reply":"2021-11-16T18:23:20.016145Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"image.size","metadata":{"execution":{"iopub.status.busy":"2021-11-16T18:23:20.018746Z","iopub.execute_input":"2021-11-16T18:23:20.019385Z","iopub.status.idle":"2021-11-16T18:23:20.028910Z","shell.execute_reply.started":"2021-11-16T18:23:20.019317Z","shell.execute_reply":"2021-11-16T18:23:20.027604Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Your code here; transform the image files and then load them into Keras as tensors \n# (be sure to perform a train-val-test split)\nimport keras\n\n# Instantiating a generator object and normalizing the RGB values\ntraingen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\ntestgen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\nvalgen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n\ntrain_data = traingen.flow_from_directory(\n    directory='../input/chest-xray-pneumonia/chest_xray/train',\n    target_size=(150, 150),\n    class_mode='binary',\n    batch_size=20,\n    seed=42\n)\n\ntest_data = testgen.flow_from_directory(\n    directory='../input/chest-xray-pneumonia/chest_xray/test',\n    target_size=(150, 150),\n    class_mode='binary',\n    batch_size=20,\n    seed=42\n)\n\nval_data = valgen.flow_from_directory(\n    directory='../input/chest-xray-pneumonia/chest_xray/val',\n    target_size=(150, 150),\n    class_mode='binary',\n    batch_size=20,\n    seed=42\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T18:23:20.031167Z","iopub.execute_input":"2021-11-16T18:23:20.031543Z","iopub.status.idle":"2021-11-16T18:23:28.124717Z","shell.execute_reply.started":"2021-11-16T18:23:20.031496Z","shell.execute_reply":"2021-11-16T18:23:28.123726Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"input_shape = (150,150,3)\noutput_shape = 2","metadata":{"execution":{"iopub.status.busy":"2021-11-16T18:23:28.126843Z","iopub.execute_input":"2021-11-16T18:23:28.127126Z","iopub.status.idle":"2021-11-16T18:23:28.134112Z","shell.execute_reply.started":"2021-11-16T18:23:28.127094Z","shell.execute_reply":"2021-11-16T18:23:28.131191Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Model building in a single list\nbaseline = keras.Sequential(\n    [\n        keras.Input(shape=input_shape), # Don't always need this input separately\n        layers.Flatten(), # need to flatten our images to be one long array\n        layers.Dense(64, activation=\"tanh\"),\n        layers.Dense(1, activation=\"sigmoid\"), #sigmoid for binary\n    ])\n\nbaseline.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-16T18:23:28.136313Z","iopub.execute_input":"2021-11-16T18:23:28.137076Z","iopub.status.idle":"2021-11-16T18:23:28.362952Z","shell.execute_reply.started":"2021-11-16T18:23:28.137015Z","shell.execute_reply":"2021-11-16T18:23:28.361771Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"batch_size = 20\nepochs = 10\n\n# Compiling our model\nbaseline.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"acc\"])\n#loss different for binary","metadata":{"execution":{"iopub.status.busy":"2021-11-16T18:23:28.365227Z","iopub.execute_input":"2021-11-16T18:23:28.365592Z","iopub.status.idle":"2021-11-16T18:23:28.386567Z","shell.execute_reply.started":"2021-11-16T18:23:28.365545Z","shell.execute_reply":"2021-11-16T18:23:28.385413Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"baseline_results = baseline.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T18:23:28.388895Z","iopub.execute_input":"2021-11-16T18:23:28.390591Z","iopub.status.idle":"2021-11-16T18:31:00.214018Z","shell.execute_reply.started":"2021-11-16T18:23:28.390530Z","shell.execute_reply":"2021-11-16T18:31:00.212882Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"baseline_results.history","metadata":{"execution":{"iopub.status.busy":"2021-11-16T18:31:00.216987Z","iopub.execute_input":"2021-11-16T18:31:00.217352Z","iopub.status.idle":"2021-11-16T18:31:00.225726Z","shell.execute_reply.started":"2021-11-16T18:31:00.217287Z","shell.execute_reply":"2021-11-16T18:31:00.224960Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Defining a results visualization function\ndef visualize_training_results(history):\n    '''\n    From https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n    \n    Input: keras history object (output from trained model)\n    '''\n    fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n    fig.suptitle('Model Results')\n\n    # summarize history for accuracy\n    ax1.plot(history.history['acc'])\n    ax1.plot(history.history['val_acc'])\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['train', 'test'], loc='upper left')\n    # summarize history for loss\n    ax2.plot(history.history['loss'])\n    ax2.plot(history.history['val_loss'])\n    ax2.set_ylabel('Loss')\n    ax2.legend(['train', 'test'], loc='upper left')\n    \n    plt.xlabel('Epoch')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-16T18:31:00.227002Z","iopub.execute_input":"2021-11-16T18:31:00.227666Z","iopub.status.idle":"2021-11-16T18:31:00.239385Z","shell.execute_reply.started":"2021-11-16T18:31:00.227623Z","shell.execute_reply":"2021-11-16T18:31:00.238574Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"score = baseline.evaluate(test_data, verbose=0)\nprint(\"Test loss:\", score[0])\nprint(\"Test accuracy:\", score[1])\n\nvisualize_training_results(baseline_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-16T18:31:00.240710Z","iopub.execute_input":"2021-11-16T18:31:00.241027Z","iopub.status.idle":"2021-11-16T18:31:07.290035Z","shell.execute_reply.started":"2021-11-16T18:31:00.240987Z","shell.execute_reply":"2021-11-16T18:31:07.289378Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}