{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-11-18T20:02:51.300581Z","iopub.execute_input":"2021-11-18T20:02:51.300882Z","iopub.status.idle":"2021-11-18T20:02:59.220395Z","shell.execute_reply.started":"2021-11-18T20:02:51.300850Z","shell.execute_reply":"2021-11-18T20:02:59.219827Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# General imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\nimport seaborn as sns\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.metrics import confusion_matrix\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2021-11-18T21:33:21.178787Z","iopub.execute_input":"2021-11-18T21:33:21.179254Z","iopub.status.idle":"2021-11-18T21:33:21.185200Z","shell.execute_reply.started":"2021-11-18T21:33:21.179211Z","shell.execute_reply":"2021-11-18T21:33:21.184420Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"# graphing of accuracy and loss from Lindsey's Neural\ndef visualize_training_results(history):\n    '''\n    From https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n    \n    Input: keras history object (output from trained model)\n    '''\n    fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n    fig.suptitle('Model Results')\n\n    # summarize history for accuracy\n    ax1.plot(history.history['acc'])\n    ax1.plot(history.history['val_acc'])\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['train', 'test'], loc='upper left')\n    # summarize history for loss\n    ax2.plot(history.history['loss'])\n    ax2.plot(history.history['val_loss'])\n    ax2.set_ylabel('Loss')\n    ax2.legend(['train', 'test'], loc='upper left')\n    \n    plt.xlabel('Epoch')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T20:03:16.490823Z","iopub.execute_input":"2021-11-18T20:03:16.491519Z","iopub.status.idle":"2021-11-18T20:03:16.497946Z","shell.execute_reply.started":"2021-11-18T20:03:16.491475Z","shell.execute_reply":"2021-11-18T20:03:16.497220Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"**Business Problem:**\nMake a decision support tool for ER physicians looking at X_rays regarding lung issues for the first time","metadata":{}},{"cell_type":"markdown","source":"**Data Understanding**\n- Because we want to train a neural network to help identify whether or not a subject has pneumonia or not based on a chest X-ray, this dataset of 5,232 chest X-rays from children will help us train the network and so that it can be of use to doctors. There are 3,883 pneumonia x-rays and 1,349 normal ones, so there is a class imbalance issue. Additionally, each image is a different size, so it is necessary to standardize the images before modelling. \n- In the context of this data, a false positive would mean that the neural network identifies an x-ray as showing evidence of pneumonia, when it is really a normal x-ray. A false negative would mean that the neural network identifies a pneumonia image as being normal.","metadata":{}},{"cell_type":"markdown","source":"**Loading an Image, to see what it looks like**","metadata":{}},{"cell_type":"code","source":"import PIL","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:47.63001Z","iopub.execute_input":"2021-11-18T00:41:47.630375Z","iopub.status.idle":"2021-11-18T00:41:47.646207Z","shell.execute_reply.started":"2021-11-18T00:41:47.630338Z","shell.execute_reply":"2021-11-18T00:41:47.645444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = PIL.Image.open('../input/chest-xray-pneumonia/chest_xray/test/NORMAL/IM-0001-0001.jpeg')","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:47.649029Z","iopub.execute_input":"2021-11-18T00:41:47.6496Z","iopub.status.idle":"2021-11-18T00:41:47.672426Z","shell.execute_reply.started":"2021-11-18T00:41:47.649562Z","shell.execute_reply":"2021-11-18T00:41:47.671756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:47.673833Z","iopub.execute_input":"2021-11-18T00:41:47.674092Z","iopub.status.idle":"2021-11-18T00:41:48.248186Z","shell.execute_reply.started":"2021-11-18T00:41:47.674056Z","shell.execute_reply":"2021-11-18T00:41:48.247459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image.size","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:48.249413Z","iopub.execute_input":"2021-11-18T00:41:48.250112Z","iopub.status.idle":"2021-11-18T00:41:48.256765Z","shell.execute_reply.started":"2021-11-18T00:41:48.250069Z","shell.execute_reply":"2021-11-18T00:41:48.255853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Setting up a Generator to Load and Reshape Images**","metadata":{}},{"cell_type":"code","source":"# Your code here; transform the image files and then load them into Keras as tensors \n# (be sure to perform a train-val-test split)\nimport keras\n\n# Instantiating a generator object and normalizing the RGB values\ntraingen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\ntestgen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\nvalgen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n\ntrain_data = traingen.flow_from_directory(\n    directory='../input/chest-xray-pneumonia/chest_xray/train',\n    target_size=(150, 150),\n    class_mode='binary',\n    batch_size=20,\n    shuffle=True,\n    seed=42\n)\ntrain_labels = []\nbatch_index1 = 0\n\n#while batch_index1 <= train_data.batch_index:\n    #x1, y1 = train_data.next()\n    #for i in range(len(y1)):\n        #train_labels.extend(y1)\n    #batch_index1 = batch_index1 + 1\n\n\ntest_data = testgen.flow_from_directory(\n    directory='../input/chest-xray-pneumonia/chest_xray/test',\n    target_size=(150, 150),\n    class_mode='binary',\n    batch_size=20,\n    shuffle=True,\n    seed=42\n)\n#test_labels = []\n#batch_index2 = 0\n\n#while batch_index2 <= test_data.batch_index:\n    #x2, y2 = test_data.next()\n    #for i in range(len(y2)):\n        #test_labels.extend(y2)\n    #batch_index2 = batch_index2 + 1\n\nval_data = valgen.flow_from_directory(\n    directory='../input/chest-xray-pneumonia/chest_xray/val',\n    target_size=(150, 150),\n    class_mode='binary',\n    batch_size=20,\n    shuffle=True,\n    seed=42\n)\n#val_labels = []\n#batch_index3 = 0\n\n#while batch_index3 <= val_data.batch_index:\n    #x3, y3 = val_data.next()\n    #for i in range(len(y3)):\n        #val_labels.extend(y3)\n    #batch_index3 = batch_index3 + 1","metadata":{"execution":{"iopub.status.busy":"2021-11-18T21:12:11.988154Z","iopub.execute_input":"2021-11-18T21:12:11.988420Z","iopub.status.idle":"2021-11-18T21:12:13.167827Z","shell.execute_reply.started":"2021-11-18T21:12:11.988390Z","shell.execute_reply":"2021-11-18T21:12:13.167163Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"# from https://www.kaggle.com/madz2000/pneumonia-detection-using-cnn-92-6-accuracy#Loading-the-Dataset\nlabels = ['PNEUMONIA', 'NORMAL']\nimg_size = 150\ndef get_training_data(data_dir):\n    data = [] \n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n                data.append([resized_arr, class_num])\n            except Exception as e:\n                print(e)\n    return np.array(data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T20:11:31.572302Z","iopub.execute_input":"2021-11-18T20:11:31.572711Z","iopub.status.idle":"2021-11-18T20:11:31.582086Z","shell.execute_reply.started":"2021-11-18T20:11:31.572672Z","shell.execute_reply":"2021-11-18T20:11:31.581304Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"training = get_training_data('../input/chest-xray-pneumonia/chest_xray/train')\ntesting = get_training_data('../input/chest-xray-pneumonia/chest_xray/test')\nvalidating = get_training_data('../input/chest-xray-pneumonia/chest_xray/val')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-18T20:23:36.064396Z","iopub.execute_input":"2021-11-18T20:23:36.064669Z","iopub.status.idle":"2021-11-18T20:24:24.428311Z","shell.execute_reply.started":"2021-11-18T20:23:36.064620Z","shell.execute_reply":"2021-11-18T20:24:24.427564Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"training[0][1]","metadata":{"execution":{"iopub.status.busy":"2021-11-18T20:59:50.516760Z","iopub.execute_input":"2021-11-18T20:59:50.517016Z","iopub.status.idle":"2021-11-18T20:59:50.523243Z","shell.execute_reply.started":"2021-11-18T20:59:50.516988Z","shell.execute_reply":"2021-11-18T20:59:50.522528Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"training_labels = []\nfor x, y in training:\n    training_labels.append(y)\nlen(training_labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T20:24:47.038099Z","iopub.execute_input":"2021-11-18T20:24:47.039022Z","iopub.status.idle":"2021-11-18T20:24:47.054737Z","shell.execute_reply.started":"2021-11-18T20:24:47.038947Z","shell.execute_reply":"2021-11-18T20:24:47.054054Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"testing_labels2 = []\nfor x, y in testing:\n    testing_labels2.append(y)\nlen(testing_labels2)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T20:27:30.314484Z","iopub.execute_input":"2021-11-18T20:27:30.315178Z","iopub.status.idle":"2021-11-18T20:27:30.322552Z","shell.execute_reply.started":"2021-11-18T20:27:30.315140Z","shell.execute_reply":"2021-11-18T20:27:30.321844Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"validating_labels = []\nfor x, y in validating:\n    validating_labels.append(y)\nlen(validating_labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T20:28:31.093878Z","iopub.execute_input":"2021-11-18T20:28:31.094132Z","iopub.status.idle":"2021-11-18T20:28:31.101156Z","shell.execute_reply.started":"2021-11-18T20:28:31.094104Z","shell.execute_reply":"2021-11-18T20:28:31.100488Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"**EDA**","metadata":{}},{"cell_type":"code","source":"(train_data.class_indices)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:49.582308Z","iopub.execute_input":"2021-11-18T00:41:49.582725Z","iopub.status.idle":"2021-11-18T00:41:49.589426Z","shell.execute_reply.started":"2021-11-18T00:41:49.582664Z","shell.execute_reply":"2021-11-18T00:41:49.588334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = pd.DataFrame(train_data.classes)\nvalues = classes.value_counts()\nclass_dict = {0:'Normal', 1:'Pneumonia'}","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:49.591155Z","iopub.execute_input":"2021-11-18T00:41:49.592174Z","iopub.status.idle":"2021-11-18T00:41:49.607493Z","shell.execute_reply.started":"2021-11-18T00:41:49.592112Z","shell.execute_reply":"2021-11-18T00:41:49.606752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes[0] = classes[0].map(class_dict)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:49.608932Z","iopub.execute_input":"2021-11-18T00:41:49.60933Z","iopub.status.idle":"2021-11-18T00:41:49.61899Z","shell.execute_reply.started":"2021-11-18T00:41:49.609292Z","shell.execute_reply":"2021-11-18T00:41:49.618186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diag = classes[0].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:49.62197Z","iopub.execute_input":"2021-11-18T00:41:49.622678Z","iopub.status.idle":"2021-11-18T00:41:49.628045Z","shell.execute_reply.started":"2021-11-18T00:41:49.622645Z","shell.execute_reply":"2021-11-18T00:41:49.627105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.set(font_scale=1.4)\nsns.barplot(diag.index, diag.values)\nplt.ylabel(\"Number of Images\")\nplt.title('Distribution of Chest X-ray Images');","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:45:10.835363Z","iopub.execute_input":"2021-11-18T00:45:10.835615Z","iopub.status.idle":"2021-11-18T00:45:11.067596Z","shell.execute_reply.started":"2021-11-18T00:45:10.835587Z","shell.execute_reply":"2021-11-18T00:45:11.065757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Baseline Model**","metadata":{}},{"cell_type":"code","source":"\n#baseline_model = keras.Sequential(name='dense')\n#baseline_model.add(Dense(500, activation='relu', input_shape=(150,150, 3))\n#baseline_model.add(Dense(250, activation='relu'))\n#baseline_model.add(Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:50:20.077767Z","iopub.execute_input":"2021-11-18T00:50:20.078045Z","iopub.status.idle":"2021-11-18T00:50:20.081384Z","shell.execute_reply.started":"2021-11-18T00:50:20.078016Z","shell.execute_reply":"2021-11-18T00:50:20.08056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input shape to be used in all models\ninput_shape = (150,150,3)\noutput_shape = 1","metadata":{"execution":{"iopub.status.busy":"2021-11-18T18:58:34.052685Z","iopub.execute_input":"2021-11-18T18:58:34.053316Z","iopub.status.idle":"2021-11-18T18:58:34.057197Z","shell.execute_reply.started":"2021-11-18T18:58:34.053283Z","shell.execute_reply":"2021-11-18T18:58:34.056290Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"baseline = keras.Sequential(\n    [\n        keras.Input(shape=input_shape), # Don't always need this input separately\n        layers.Flatten(), # need to flatten our images to be one long array\n        layers.Dense(100, activation=\"relu\"),\n        layers.Dense(output_shape, activation=\"sigmoid\"),\n    ])\n\nbaseline.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:50:20.093963Z","iopub.execute_input":"2021-11-18T00:50:20.09419Z","iopub.status.idle":"2021-11-18T00:50:22.516545Z","shell.execute_reply.started":"2021-11-18T00:50:20.094158Z","shell.execute_reply":"2021-11-18T00:50:22.515769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline.compile(optimizer='adam',\n                      loss='binary_crossentropy',\n                      metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:50:22.518022Z","iopub.execute_input":"2021-11-18T00:50:22.518479Z","iopub.status.idle":"2021-11-18T00:50:22.530633Z","shell.execute_reply.started":"2021-11-18T00:50:22.518438Z","shell.execute_reply":"2021-11-18T00:50:22.52984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nbaseline_results = baseline.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data,)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:50:22.533657Z","iopub.execute_input":"2021-11-18T00:50:22.534356Z","iopub.status.idle":"2021-11-18T00:57:25.831261Z","shell.execute_reply.started":"2021-11-18T00:50:22.534313Z","shell.execute_reply":"2021-11-18T00:57:25.830518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_results.history","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:57:25.832786Z","iopub.execute_input":"2021-11-18T00:57:25.83331Z","iopub.status.idle":"2021-11-18T00:57:25.840184Z","shell.execute_reply.started":"2021-11-18T00:57:25.833269Z","shell.execute_reply":"2021-11-18T00:57:25.839465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(baseline_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:57:25.841748Z","iopub.execute_input":"2021-11-18T00:57:25.842241Z","iopub.status.idle":"2021-11-18T00:57:26.17316Z","shell.execute_reply.started":"2021-11-18T00:57:25.842204Z","shell.execute_reply":"2021-11-18T00:57:26.172392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model is definitely overfit, because the accuracy in training data is much higher than that of the validation data. This is a very simple neural network, and so it could benefit from adding another layer to learn patterns from. This might also help decrease loss.","metadata":{}},{"cell_type":"markdown","source":"**Adding another layer**","metadata":{}},{"cell_type":"code","source":"# Adding in the layers\ntwo_hidden = keras.Sequential(\n    [\n        keras.Input(shape=input_shape), # Don't always need this input separately\n        layers.Flatten(), # need to flatten our images to be one long array\n        layers.Dense(100, activation='relu'),\n        layers.Dense(50, activation='relu'),\n        layers.Dense(output_shape, activation=\"sigmoid\"),\n    ])\n\ntwo_hidden.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:57:26.1744Z","iopub.execute_input":"2021-11-18T00:57:26.17685Z","iopub.status.idle":"2021-11-18T00:57:26.214648Z","shell.execute_reply.started":"2021-11-18T00:57:26.176808Z","shell.execute_reply":"2021-11-18T00:57:26.213937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compiling the two-layer model\ntwo_hidden.compile(optimizer='adam',\n                      loss='binary_crossentropy',\n                      metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:57:26.215807Z","iopub.execute_input":"2021-11-18T00:57:26.216061Z","iopub.status.idle":"2021-11-18T00:57:26.227173Z","shell.execute_reply.started":"2021-11-18T00:57:26.216025Z","shell.execute_reply":"2021-11-18T00:57:26.226435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the two-layer model \ntwo_hidden_results = two_hidden.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:57:26.228944Z","iopub.execute_input":"2021-11-18T00:57:26.229234Z","iopub.status.idle":"2021-11-18T01:03:13.238939Z","shell.execute_reply.started":"2021-11-18T00:57:26.229198Z","shell.execute_reply":"2021-11-18T01:03:13.23802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(two_hidden_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:03:13.242004Z","iopub.execute_input":"2021-11-18T01:03:13.24251Z","iopub.status.idle":"2021-11-18T01:03:13.584292Z","shell.execute_reply.started":"2021-11-18T01:03:13.242466Z","shell.execute_reply":"2021-11-18T01:03:13.583544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once again, the model is overfit. Also, judging from this graph showing the accuracy and loss for both training and validation data, it looks like it could benefit from a greater number of training epochs, since it looks like the validation loss might decrease further.","metadata":{}},{"cell_type":"markdown","source":"**Double the number of epochs**","metadata":{}},{"cell_type":"code","source":"# Adding in the layers\nmore_epochs = keras.Sequential(\n    [\n        keras.Input(shape=input_shape), # Don't always need this input separately\n        layers.Flatten(), # need to flatten our images to be one long array\n        layers.Dense(100, activation='relu'),\n        layers.Dense(50, activation='relu'),\n        layers.Dense(output_shape, activation=\"sigmoid\"),\n    ])\n\nmore_epochs.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:03:13.58584Z","iopub.execute_input":"2021-11-18T01:03:13.586326Z","iopub.status.idle":"2021-11-18T01:03:13.624069Z","shell.execute_reply.started":"2021-11-18T01:03:13.586287Z","shell.execute_reply":"2021-11-18T01:03:13.62336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compiling the two-layer model\nmore_epochs.compile(optimizer='adam',\n                      loss='binary_crossentropy',\n                      metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:03:13.625273Z","iopub.execute_input":"2021-11-18T01:03:13.625609Z","iopub.status.idle":"2021-11-18T01:03:13.635469Z","shell.execute_reply.started":"2021-11-18T01:03:13.625571Z","shell.execute_reply":"2021-11-18T01:03:13.63452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the two-layer model \nmore_epochs_results = more_epochs.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=30,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:03:13.640642Z","iopub.execute_input":"2021-11-18T01:03:13.640867Z","iopub.status.idle":"2021-11-18T01:22:42.814775Z","shell.execute_reply.started":"2021-11-18T01:03:13.640842Z","shell.execute_reply":"2021-11-18T01:22:42.81398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(more_epochs_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:22:42.816372Z","iopub.execute_input":"2021-11-18T01:22:42.816632Z","iopub.status.idle":"2021-11-18T01:22:43.357931Z","shell.execute_reply.started":"2021-11-18T01:22:42.816594Z","shell.execute_reply":"2021-11-18T01:22:43.357136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once again, the model is overfitting. It also looks like the loss is oscillating a good deal, but not necessarily decreasing. It is probably time to try a Convolutional model, especially since this is an image classification problem. Adding convolutions will put filters on the images to help the model pick up on patterns better.","metadata":{}},{"cell_type":"markdown","source":"**Building a Convolutional Neural Network**","metadata":{}},{"cell_type":"code","source":"# Set up for this CNN model is from this blog:  https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\ncnn = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn.add(layers.MaxPooling2D((2, 2)))\ncnn.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn.add(layers.MaxPooling2D((2, 2)))\ncnn.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn.add(layers.Flatten())\ncnn.add(layers.Dense(128, activation='relu'))\ncnn.add(layers.Dense(1, activation='sigmoid'))\n\ncnn.compile(loss='binary_crossentropy',\n            optimizer=\"adam\",\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T04:18:40.388748Z","iopub.execute_input":"2021-11-18T04:18:40.389054Z","iopub.status.idle":"2021-11-18T04:18:40.548645Z","shell.execute_reply.started":"2021-11-18T04:18:40.38902Z","shell.execute_reply":"2021-11-18T04:18:40.54762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T04:18:44.982067Z","iopub.execute_input":"2021-11-18T04:18:44.982387Z","iopub.status.idle":"2021-11-18T04:18:45.001435Z","shell.execute_reply.started":"2021-11-18T04:18:44.982343Z","shell.execute_reply":"2021-11-18T04:18:45.000482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_results = cnn.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T04:18:47.783186Z","iopub.execute_input":"2021-11-18T04:18:47.783817Z","iopub.status.idle":"2021-11-18T04:25:51.252942Z","shell.execute_reply.started":"2021-11-18T04:18:47.78378Z","shell.execute_reply":"2021-11-18T04:25:51.251981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T04:27:20.890858Z","iopub.execute_input":"2021-11-18T04:27:20.891213Z","iopub.status.idle":"2021-11-18T04:27:21.256035Z","shell.execute_reply.started":"2021-11-18T04:27:20.891171Z","shell.execute_reply":"2021-11-18T04:27:21.255056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This cnn models requires much improvement, because it is overfitting and as the training accuracy increases, the testing accuracy decreases, and as the training loss decreasesthe testing loss increases quite a lot.\nReading the keras documentation for adam optimizers, there was a note discussing how for some types of CNN models, the default value for the hyperparameter epsilon in adam (1e-7) may not be the best; they suggest trying bigger values such as 0.1 or 1, so I will try this in the next model.","metadata":{}},{"cell_type":"markdown","source":"**CNN with a bigger epsilon (0.1)**","metadata":{}},{"cell_type":"code","source":"adam_ep = keras.optimizers.Adam(epsilon=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T21:33:36.043577Z","iopub.execute_input":"2021-11-18T21:33:36.044151Z","iopub.status.idle":"2021-11-18T21:33:36.047961Z","shell.execute_reply.started":"2021-11-18T21:33:36.044112Z","shell.execute_reply":"2021-11-18T21:33:36.047131Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_ep = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_ep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_ep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_ep.add(layers.MaxPooling2D((2, 2)))\ncnn_ep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_ep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_ep.add(layers.MaxPooling2D((2, 2)))\ncnn_ep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_ep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_ep.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_ep.add(layers.Flatten())\ncnn_ep.add(layers.Dense(128, activation='relu'))\ncnn_ep.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_ep.compile(loss='binary_crossentropy',\n            optimizer= adam_ep,\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T04:33:16.203228Z","iopub.execute_input":"2021-11-18T04:33:16.203541Z","iopub.status.idle":"2021-11-18T04:33:16.316191Z","shell.execute_reply.started":"2021-11-18T04:33:16.203509Z","shell.execute_reply":"2021-11-18T04:33:16.315208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_ep = cnn_ep.fit_generator(train_data,\n                              steps_per_epoch=50,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T04:33:22.525493Z","iopub.execute_input":"2021-11-18T04:33:22.52578Z","iopub.status.idle":"2021-11-18T04:36:43.637777Z","shell.execute_reply.started":"2021-11-18T04:33:22.525748Z","shell.execute_reply":"2021-11-18T04:36:43.636714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_ep)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T04:36:49.614702Z","iopub.execute_input":"2021-11-18T04:36:49.615002Z","iopub.status.idle":"2021-11-18T04:36:49.966179Z","shell.execute_reply.started":"2021-11-18T04:36:49.614969Z","shell.execute_reply":"2021-11-18T04:36:49.965106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Increasing the epsilon value seems to reduce the validation data loss, and to increase the validation data accuracy. It also seems to reduce some of the overfitting that was taking place in previous models. It would also be interesting to see what changing the learning rate does to the model.","metadata":{}},{"cell_type":"markdown","source":"**CNN with a bigger epsilon (0.1) and smaller learning rate (0.0001)**","metadata":{}},{"cell_type":"code","source":"adam_lep = keras.optimizers.Adam(learning_rate=0.0001, epsilon=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T21:33:42.212622Z","iopub.execute_input":"2021-11-18T21:33:42.212914Z","iopub.status.idle":"2021-11-18T21:33:42.216706Z","shell.execute_reply.started":"2021-11-18T21:33:42.212884Z","shell.execute_reply":"2021-11-18T21:33:42.216001Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_lep = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_lep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_lep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_lep.add(layers.MaxPooling2D((2, 2)))\ncnn_lep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_lep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_lep.add(layers.MaxPooling2D((2, 2)))\ncnn_lep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_lep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_lep.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_lep.add(layers.Flatten())\ncnn_lep.add(layers.Dense(128, activation='relu'))\ncnn_lep.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_lep.compile(loss='binary_crossentropy',\n            optimizer= adam_lep,\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T21:33:46.627056Z","iopub.execute_input":"2021-11-18T21:33:46.627313Z","iopub.status.idle":"2021-11-18T21:33:46.713612Z","shell.execute_reply.started":"2021-11-18T21:33:46.627286Z","shell.execute_reply":"2021-11-18T21:33:46.712933Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"cnn_lep_results = cnn_lep.fit_generator(train_data,\n                              steps_per_epoch=50,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T21:33:51.990967Z","iopub.execute_input":"2021-11-18T21:33:51.993706Z","iopub.status.idle":"2021-11-18T21:36:45.400654Z","shell.execute_reply.started":"2021-11-18T21:33:51.993667Z","shell.execute_reply":"2021-11-18T21:36:45.399952Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_lep_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T21:36:50.329645Z","iopub.execute_input":"2021-11-18T21:36:50.330177Z","iopub.status.idle":"2021-11-18T21:36:50.630768Z","shell.execute_reply.started":"2021-11-18T21:36:50.330143Z","shell.execute_reply":"2021-11-18T21:36:50.630128Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":"Decreasing the learning rate did not have a good effect on the model; it is clearly still overfitting and the testing accuracy ","metadata":{}},{"cell_type":"markdown","source":"**CNN with changed epsilon and L2 regularization**","metadata":{}},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_rep = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_rep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_rep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_rep.add(layers.MaxPooling2D((2, 2)))\ncnn_rep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_rep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_rep.add(layers.MaxPooling2D((2, 2)))\ncnn_rep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_rep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_rep.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_rep.add(layers.Flatten())\ncnn_rep.add(layers.Dense(128, kernel_regularizer= regularizers.l2(0.01), activation='relu'))\ncnn_rep.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_rep.compile(loss='binary_crossentropy',\n            optimizer= adam_ep,\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T21:37:11.327354Z","iopub.execute_input":"2021-11-18T21:37:11.327613Z","iopub.status.idle":"2021-11-18T21:37:11.412233Z","shell.execute_reply.started":"2021-11-18T21:37:11.327585Z","shell.execute_reply":"2021-11-18T21:37:11.411564Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"cnn_rep = cnn_rep.fit_generator(train_data,\n                              steps_per_epoch=50,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T21:37:15.889477Z","iopub.execute_input":"2021-11-18T21:37:15.890308Z","iopub.status.idle":"2021-11-18T21:40:30.762814Z","shell.execute_reply.started":"2021-11-18T21:37:15.890268Z","shell.execute_reply":"2021-11-18T21:40:30.762058Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":"**CNN with changed epsilon and L1 regularization**","metadata":{}},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_r1ep = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_r1ep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_r1ep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_r1ep.add(layers.MaxPooling2D((2, 2)))\ncnn_r1ep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_r1ep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_r1ep.add(layers.MaxPooling2D((2, 2)))\ncnn_r1ep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_r1ep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_r1ep.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_r1ep.add(layers.Flatten())\ncnn_r1ep.add(layers.Dense(128, kernel_regularizer= regularizers.l1(0.01), activation='relu'))\ncnn_r1ep.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_r1ep.compile(loss='binary_crossentropy',\n            optimizer= adam_ep,\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:28:30.17479Z","iopub.status.idle":"2021-11-18T01:28:30.175556Z","shell.execute_reply.started":"2021-11-18T01:28:30.175286Z","shell.execute_reply":"2021-11-18T01:28:30.175315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_r1ep = cnn_r1ep.fit_generator(train_data,\n                              steps_per_epoch=50,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:28:30.177018Z","iopub.status.idle":"2021-11-18T01:28:30.177663Z","shell.execute_reply.started":"2021-11-18T01:28:30.177429Z","shell.execute_reply":"2021-11-18T01:28:30.177453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CNN model with changed epsilon and added Dense layer**","metadata":{}},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_dep = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_dep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_dep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_dep.add(layers.MaxPooling2D((2, 2)))\ncnn_dep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_dep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_dep.add(layers.MaxPooling2D((2, 2)))\ncnn_dep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_dep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_dep.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_dep.add(layers.Flatten())\ncnn_dep.add(layers.Dense(128, activation='relu'))\ncnn_dep.add(layers.Dense(64, activation='relu'))\ncnn_dep.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_dep.compile(loss='binary_crossentropy',\n            optimizer= adam_ep,\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:28:30.178917Z","iopub.status.idle":"2021-11-18T01:28:30.179528Z","shell.execute_reply.started":"2021-11-18T01:28:30.179291Z","shell.execute_reply":"2021-11-18T01:28:30.179315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_dep = cnn_dep.fit_generator(train_data,\n                              steps_per_epoch=50,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:28:30.180964Z","iopub.status.idle":"2021-11-18T01:28:30.181681Z","shell.execute_reply.started":"2021-11-18T01:28:30.181399Z","shell.execute_reply":"2021-11-18T01:28:30.181427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CNN model with changed epsilon, added layer, and dropout layers**","metadata":{}},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_ddep = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_ddep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_ddep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_ddep.add(layers.MaxPooling2D((2, 2)))\ncnn_ddep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_ddep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_ddep.add(layers.MaxPooling2D((2, 2)))\ncnn_ddep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_ddep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_ddep.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_ddep.add(layers.Flatten())\ncnn_ddep.add(layers.Dense(128, activation='relu'))\ncnn_ddep.add(layers.Dropout(0.25))\ncnn_ddep.add(layers.Dense(64, activation='relu'))\ncnn_ddep.add(layers.Dropout(0.25))\ncnn_ddep.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_ddep.compile(loss='binary_crossentropy',\n            optimizer= adam_ep,\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:28:30.18308Z","iopub.status.idle":"2021-11-18T01:28:30.183746Z","shell.execute_reply.started":"2021-11-18T01:28:30.183492Z","shell.execute_reply":"2021-11-18T01:28:30.183516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_ddep = cnn_ddep.fit_generator(train_data,\n                              steps_per_epoch=50,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:28:30.185084Z","iopub.status.idle":"2021-11-18T01:28:30.18575Z","shell.execute_reply.started":"2021-11-18T01:28:30.185487Z","shell.execute_reply":"2021-11-18T01:28:30.185513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CNN model with normal epsilon, added layers, added Dropout layers**","metadata":{}},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_dd = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_dd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_dd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_dd.add(layers.MaxPooling2D((2, 2)))\ncnn_dd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_dd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_dd.add(layers.MaxPooling2D((2, 2)))\ncnn_dd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_dd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_dd.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_dd.add(layers.Flatten())\ncnn_dd.add(layers.Dense(128, activation='relu'))\ncnn_dd.add(layers.Dropout(0.25))\ncnn_dd.add(layers.Dense(64, activation='relu'))\ncnn_dd.add(layers.Dropout(0.25))\ncnn_dd.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_dd.compile(loss='binary_crossentropy',\n            optimizer= 'adam',\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:28:30.186981Z","iopub.status.idle":"2021-11-18T01:28:30.187599Z","shell.execute_reply.started":"2021-11-18T01:28:30.187354Z","shell.execute_reply":"2021-11-18T01:28:30.187377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_dd = cnn_dd.fit_generator(train_data,\n                              steps_per_epoch=50,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:28:30.18893Z","iopub.status.idle":"2021-11-18T01:28:30.189576Z","shell.execute_reply.started":"2021-11-18T01:28:30.189328Z","shell.execute_reply":"2021-11-18T01:28:30.189354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_dd)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:28:30.190975Z","iopub.status.idle":"2021-11-18T01:28:30.191636Z","shell.execute_reply.started":"2021-11-18T01:28:30.191388Z","shell.execute_reply":"2021-11-18T01:28:30.191412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CNN model with SGD, normal epsilon, added layers, added Dropout layers**","metadata":{}},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_sdd = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_sdd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_sdd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_sdd.add(layers.MaxPooling2D((2, 2)))\ncnn_sdd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_sdd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_sdd.add(layers.MaxPooling2D((2, 2)))\ncnn_sdd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_sdd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_sdd.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_sdd.add(layers.Flatten())\ncnn_sdd.add(layers.Dense(128, activation='relu'))\ncnn_sdd.add(layers.Dropout(0.25))\ncnn_sdd.add(layers.Dense(64, activation='relu'))\ncnn_sdd.add(layers.Dropout(0.25))\ncnn_sdd.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_sdd.compile(loss='binary_crossentropy',\n            optimizer= 'sgd',\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:28:30.192918Z","iopub.status.idle":"2021-11-18T01:28:30.193529Z","shell.execute_reply.started":"2021-11-18T01:28:30.193293Z","shell.execute_reply":"2021-11-18T01:28:30.193317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_sdd = cnn_sdd.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:28:30.194735Z","iopub.status.idle":"2021-11-18T01:28:30.195446Z","shell.execute_reply.started":"2021-11-18T01:28:30.195164Z","shell.execute_reply":"2021-11-18T01:28:30.195211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CNN model with fewer steps per epoch, more epochs, SGD, normal epsilon, added layers, added Dropout layers**","metadata":{}},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_smdd = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_smdd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_smdd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_smdd.add(layers.MaxPooling2D((2, 2)))\ncnn_smdd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_smdd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_smdd.add(layers.MaxPooling2D((2, 2)))\ncnn_smdd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_smdd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_smdd.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_smdd.add(layers.Flatten())\ncnn_smdd.add(layers.Dense(128, activation='relu'))\ncnn_smdd.add(layers.Dropout(0.25))\ncnn_smdd.add(layers.Dense(64, activation='relu'))\ncnn_smdd.add(layers.Dropout(0.25))\ncnn_smdd.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_smdd.compile(loss='binary_crossentropy',\n            optimizer= 'sgd',\n            metrics=['acc', 'Recall', 'Precision','TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:28:30.196798Z","iopub.status.idle":"2021-11-18T01:28:30.197418Z","shell.execute_reply.started":"2021-11-18T01:28:30.197183Z","shell.execute_reply":"2021-11-18T01:28:30.197206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_smdd_results = cnn_smdd.fit_generator(train_data,\n                              steps_per_epoch=30,\n                              epochs=50,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:28:30.198606Z","iopub.status.idle":"2021-11-18T01:28:30.19924Z","shell.execute_reply.started":"2021-11-18T01:28:30.199005Z","shell.execute_reply":"2021-11-18T01:28:30.199028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"early_stop = [EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss',\n                           save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2021-11-18T18:59:11.010830Z","iopub.execute_input":"2021-11-18T18:59:11.011151Z","iopub.status.idle":"2021-11-18T18:59:11.016377Z","shell.execute_reply.started":"2021-11-18T18:59:11.011114Z","shell.execute_reply":"2021-11-18T18:59:11.015677Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**CNN model with early stopping, fewer steps per epoch, more epochs, SGD, normal epsilon, added layers, added Dropout layers**","metadata":{}},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_esmdd = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_esmdd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_esmdd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_esmdd.add(layers.MaxPooling2D((2, 2)))\ncnn_esmdd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_esmdd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_esmdd.add(layers.MaxPooling2D((2, 2)))\ncnn_esmdd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_esmdd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_esmdd.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_esmdd.add(layers.Flatten())\ncnn_esmdd.add(layers.Dense(128, activation='relu'))\ncnn_esmdd.add(layers.Dropout(0.25))\ncnn_esmdd.add(layers.Dense(64, activation='relu'))\ncnn_esmdd.add(layers.Dropout(0.25))\ncnn_esmdd.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_esmdd.compile(loss='binary_crossentropy',\n            optimizer= 'sgd',\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T21:14:31.451593Z","iopub.execute_input":"2021-11-18T21:14:31.452315Z","iopub.status.idle":"2021-11-18T21:14:31.548591Z","shell.execute_reply.started":"2021-11-18T21:14:31.452280Z","shell.execute_reply":"2021-11-18T21:14:31.547936Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"cnn_esmdd_results = cnn_esmdd.fit_generator(train_data,\n                              steps_per_epoch=30,\n                              epochs=50,\n                              callbacks=early_stop,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T21:14:37.810272Z","iopub.execute_input":"2021-11-18T21:14:37.810810Z","iopub.status.idle":"2021-11-18T21:21:57.040158Z","shell.execute_reply.started":"2021-11-18T21:14:37.810773Z","shell.execute_reply":"2021-11-18T21:21:57.039387Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_esmdd_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T21:07:26.004031Z","iopub.execute_input":"2021-11-18T21:07:26.004292Z","iopub.status.idle":"2021-11-18T21:08:06.378600Z","shell.execute_reply.started":"2021-11-18T21:07:26.004263Z","shell.execute_reply":"2021-11-18T21:08:06.377914Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"# Pull out the best epochfor the cnn_esmdd model\nbest_cnn_esmdd = load_model('best_model.h5')\nbest_cnn_esmdd","metadata":{"execution":{"iopub.status.busy":"2021-11-18T19:05:35.413823Z","iopub.execute_input":"2021-11-18T19:05:35.414100Z","iopub.status.idle":"2021-11-18T19:05:35.551270Z","shell.execute_reply.started":"2021-11-18T19:05:35.414071Z","shell.execute_reply":"2021-11-18T19:05:35.550559Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"y_pred_cnn_esmdd = cnn_esmdd.predict(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T20:29:19.689101Z","iopub.execute_input":"2021-11-18T20:29:19.689362Z","iopub.status.idle":"2021-11-18T20:29:25.534925Z","shell.execute_reply.started":"2021-11-18T20:29:19.689333Z","shell.execute_reply":"2021-11-18T20:29:25.534105Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"y_pred_cnn_esmdd","metadata":{"execution":{"iopub.status.busy":"2021-11-18T20:29:58.297326Z","iopub.execute_input":"2021-11-18T20:29:58.297610Z","iopub.status.idle":"2021-11-18T20:29:58.318644Z","shell.execute_reply.started":"2021-11-18T20:29:58.297579Z","shell.execute_reply":"2021-11-18T20:29:58.317775Z"},"scrolled":true,"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"ypred_cnnesmdd_list= []\nfor pred in y_pred_cnn_esmdd:\n    ypred_cnnesmdd_list.extend(pred)\nlen(np.array(ypred_cnnesmdd_list))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-18T20:31:07.192009Z","iopub.execute_input":"2021-11-18T20:31:07.192561Z","iopub.status.idle":"2021-11-18T20:31:07.199780Z","shell.execute_reply.started":"2021-11-18T20:31:07.192522Z","shell.execute_reply":"2021-11-18T20:31:07.198930Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"rypred_cnnesmdd_list = np.round(ypred_cnnesmdd_list)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T20:44:24.263902Z","iopub.execute_input":"2021-11-18T20:44:24.264157Z","iopub.status.idle":"2021-11-18T20:44:24.268659Z","shell.execute_reply.started":"2021-11-18T20:44:24.264128Z","shell.execute_reply":"2021-11-18T20:44:24.267761Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"rypred_cnnesmdd_list","metadata":{"execution":{"iopub.status.busy":"2021-11-18T20:44:34.689944Z","iopub.execute_input":"2021-11-18T20:44:34.690469Z","iopub.status.idle":"2021-11-18T20:44:34.702124Z","shell.execute_reply.started":"2021-11-18T20:44:34.690432Z","shell.execute_reply":"2021-11-18T20:44:34.701469Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"confusion_matrix(np.array(testing_labels2),np.array(rypred_cnnesmdd_list), normalize='true')","metadata":{"execution":{"iopub.status.busy":"2021-11-18T20:45:27.014513Z","iopub.execute_input":"2021-11-18T20:45:27.015089Z","iopub.status.idle":"2021-11-18T20:45:27.028734Z","shell.execute_reply.started":"2021-11-18T20:45:27.015049Z","shell.execute_reply":"2021-11-18T20:45:27.027894Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}