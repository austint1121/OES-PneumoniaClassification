{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2021-11-18T22:53:50.286249Z","iopub.execute_input":"2021-11-18T22:53:50.286570Z","iopub.status.idle":"2021-11-18T22:53:50.291113Z","shell.execute_reply.started":"2021-11-18T22:53:50.286531Z","shell.execute_reply":"2021-11-18T22:53:50.290265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Technical Summary**\n","metadata":{}},{"cell_type":"markdown","source":"## **Business Understanding**\nCyclops Hospital Network (CHN) owns 4 inpatient hospitals and 27 urgent care centers. The 4 inpatient hospitals each have a pediatric emergency room. The 27 urgent care centers are equipped to perform X-ray and CT imaging and diagnosis/treat peditric patients as well. Overall, CHN thus has 31 locations where pediatric patients who potentially have viral or bacterial pneumonia may seek diagnosis and care. Given certain symptoms and the severity of those symptoms, many of those patients will undergo X-ray imaging of the thorax. Given that a radiologist has a maximum of 12 hours to review these images and the initial assessment of the imaging is done by either an emergency room physician or an urgent care practitioner, who may be less accurate in diagnosing pneumonia via imaging, CHN wishes to create a decision support tool (DST) using a neural network in order to check the assessment of the emergency room and urgent care physicians. \n\nThis DST will help to prevent doctors from missing important diagnoses and sending patients home with lack of care. Given the wide range of timescales during which pneumonia can develop, the similarly wide range of severity of symptoms and the specific dillema many pediatric patients experience in verbalizing their symptoms/health status, this DST will protect at-risk patients from being sent home without care to potentially worsen before a radiologist reviews her or his imaging. Additionally, this DST will protect CHN from malpractice suits that could result from this lack of diagnosis and subsequent lack of care.","metadata":{}},{"cell_type":"markdown","source":"## Directory Setup\nThe purpose of this section will demostrate and justify our data preperations steps used on our data. In our preperation we set up generators for our data, and in the generators we also re-scale and re-size the images before they are fed into our model.\n\nDue to the large size of our dataset, we chose to use Kaggle as a place to store our data on the cloud. Our directory setup was structured in the following format: \n```\n├── chest-xray                    <- Top level directory\n│   ├── test                      <- Test set images\n│   │   ├── Normal                <- Normal lung photos      \n│   │   │   └── ...\n│   │   └──  Pneumonia            <- Pneumonia lung photos\n│   │   │   └── ...\n│   ├── train                     <- Training set images\n│   │   ├── Normal                <- Normal lung photos \n│   │   │   └── ...\n│   │   └──  Pneumonia            <- Pneumonia lung photos\n│   │   │   └── ...\n│   ├── val                       <- Training set images\n│   │   ├── Normal                <- Normal lung photos \n│   │   │   └── ...\n│   │   └──  Pneumonia            <- Pneumonia lung photos\n│   │   │   └── ...             \n```\nThis setup allows us to use Kera's Image Data Generator to load our data. We chose to use a generator for 3 reasons:\n- Saving memory and disk space by not downloading the dataset\n- Integrating the preproccesing into our modeling process\n- Easy re-sizing and rescaling of images\nUsing generators also allows more easily reproducable results. Since images fed into our model this way do not have to be preproccessed beforehand.","metadata":{}},{"cell_type":"code","source":"# Import statements\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport keras\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:53:50.292643Z","iopub.execute_input":"2021-11-18T22:53:50.293019Z","iopub.status.idle":"2021-11-18T22:53:50.308974Z","shell.execute_reply.started":"2021-11-18T22:53:50.292971Z","shell.execute_reply":"2021-11-18T22:53:50.308396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiating a generator object and normalizing the RGB values\ntraingen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\ntestgen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\nvalgen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n\n# Creating the generator for the training data\ntrain_data = traingen.flow_from_directory(\n    # Specifying location of training data\n    directory='../input/chest-xray-pneumonia/chest_xray/train',\n    # Re-sizing images to 150x150\n    target_size=(150, 150),\n    # Class mode to binary to recoginize the two directories \"NORMAL\" and \"PNEUMONIA\" as the labels\n    class_mode='binary',\n    batch_size=20,\n    seed=42\n)\n# Creating the generator for the testing data\ntest_data = testgen.flow_from_directory(\n    # Specifying location of testing data\n    directory='../input/chest-xray-pneumonia/chest_xray/test',\n    # Re-sizing images to 150x150\n    target_size=(150, 150),\n    # Class mode to binary to recoginize the two directories \"NORMAL\" and \"PNEUMONIA\" as the labels\n    class_mode='binary',\n    batch_size=20,\n    seed=42\n)\n\n# Setting aside a validation set\nval_data = valgen.flow_from_directory(\n    # Specifying location of testing data\n    directory='../input/chest-xray-pneumonia/chest_xray/val',\n    # Re-sizing images to 150x150\n    target_size=(150, 150),\n    # Class mode to binary to recoginize the two directories \"NORMAL\" and \"PNEUMONIA\" as the labels\n    class_mode='binary',\n    batch_size=20,\n    seed=42\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:53:50.310548Z","iopub.execute_input":"2021-11-18T22:53:50.310953Z","iopub.status.idle":"2021-11-18T22:53:51.782493Z","shell.execute_reply.started":"2021-11-18T22:53:50.310906Z","shell.execute_reply":"2021-11-18T22:53:51.781786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Data Understanding**\n- Because we want to train a neural network to help identify whether or not a subject has pneumonia or not based on a chest X-ray, this dataset of 5,232 chest X-rays from children will help us train the network and so that it can be of use to doctors. There are 3,883 pneumonia x-rays and 1,349 normal ones, so there is a class imbalance issue. Additionally, each image is a different size, so it is necessary to standardize the images before modelling. \n- In the context of this data, a false positive would mean that the neural network identifies an x-ray as showing evidence of pneumonia, when it is really a normal x-ray. A false negative would mean that the neural network identifies a pneumonia image as being normal.","metadata":{}},{"cell_type":"code","source":"# Putting class information into a dataframe for easy visualizing\nclasses = pd.DataFrame(train_data.classes)\nvalues = classes.value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:53:51.783619Z","iopub.execute_input":"2021-11-18T22:53:51.783853Z","iopub.status.idle":"2021-11-18T22:53:51.791225Z","shell.execute_reply.started":"2021-11-18T22:53:51.783824Z","shell.execute_reply":"2021-11-18T22:53:51.790422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Giving the data better labels for visualization\nclass_dict = {0:'Normal', 1:'Pneumonia'}\nclasses[0] = classes[0].map(class_dict)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:53:51.793050Z","iopub.execute_input":"2021-11-18T22:53:51.793428Z","iopub.status.idle":"2021-11-18T22:53:51.808914Z","shell.execute_reply.started":"2021-11-18T22:53:51.793395Z","shell.execute_reply":"2021-11-18T22:53:51.807783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Looking at the distribution of values between x-rays that show pneumonia and those that don't\ndiag = classes[0].value_counts()\ndiag","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:53:51.810504Z","iopub.execute_input":"2021-11-18T22:53:51.810993Z","iopub.status.idle":"2021-11-18T22:53:51.825885Z","shell.execute_reply.started":"2021-11-18T22:53:51.810960Z","shell.execute_reply":"2021-11-18T22:53:51.825123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a bargraph to visualize the class imbalance\nplt.figure(figsize=(12,8))\nsns.set(font_scale=1.4)\nsns.barplot(diag.index, diag.values)\nplt.ylabel(\"Number of Images\")\nplt.title('Distribution of Chest X-ray Images');","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:53:51.827105Z","iopub.execute_input":"2021-11-18T22:53:51.827920Z","iopub.status.idle":"2021-11-18T22:53:52.079961Z","shell.execute_reply.started":"2021-11-18T22:53:51.827887Z","shell.execute_reply":"2021-11-18T22:53:52.078907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Visualize Transformation**\n\nWe will visualize the first 10 items in the training data set to check that all transformations to the images were done correctly.","metadata":{}},{"cell_type":"code","source":"# Visualize\ntrain_batch = train_data.next()\nfig, axes = plt.subplots(2, 5, figsize=(16, 8))\n    \nfor i in range(10):\n    # Load image into numpy array and re-scale\n    img = np.array(train_batch[0][i] * 255, dtype='uint8')\n    ax = axes[i // 5, i % 5]\n    ax.imshow(img)\nfig.suptitle('Training Images')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:53:52.081084Z","iopub.execute_input":"2021-11-18T22:53:52.081303Z","iopub.status.idle":"2021-11-18T22:53:54.288089Z","shell.execute_reply.started":"2021-11-18T22:53:52.081276Z","shell.execute_reply":"2021-11-18T22:53:54.287468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Multilayer Perceptron Models**\n\nWe will start by setting up a baseline multi-layer perceptron model, because this is the most simple kind of Neural Network. We will iterate off of the results, building adjusted models with the goal of obtaining an improved model each time.","metadata":{}},{"cell_type":"markdown","source":"### **Baseline Multilayer Perceptron Model**","metadata":{}},{"cell_type":"code","source":"# Setting up a baseline MLP\nbaseline = keras.Sequential(\n    [\n        keras.Input(shape=(150,150,3)), # Don't always need this input separately\n        keras.layers.Flatten(), # need to flatten our images to be one long array\n        keras.layers.Dense(100, activation=\"relu\"),\n        keras.layers.Dense(1, activation=\"sigmoid\"),\n    ])\n\nbaseline.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:53:54.289405Z","iopub.execute_input":"2021-11-18T22:53:54.289637Z","iopub.status.idle":"2021-11-18T22:53:54.364288Z","shell.execute_reply.started":"2021-11-18T22:53:54.289608Z","shell.execute_reply":"2021-11-18T22:53:54.363334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compiling the baseline MLP\nbaseline.compile(optimizer='adam',\n                      loss='binary_crossentropy',\n                      metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:53:54.365500Z","iopub.execute_input":"2021-11-18T22:53:54.365725Z","iopub.status.idle":"2021-11-18T22:53:54.375754Z","shell.execute_reply.started":"2021-11-18T22:53:54.365696Z","shell.execute_reply":"2021-11-18T22:53:54.375073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_results = baseline.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data,)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:53:54.377726Z","iopub.execute_input":"2021-11-18T22:53:54.378458Z","iopub.status.idle":"2021-11-18T22:58:54.170463Z","shell.execute_reply.started":"2021-11-18T22:53:54.378420Z","shell.execute_reply":"2021-11-18T22:58:54.169735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualizing results\n# Creating figure with 2 subplots\ndef visualize_results(results):\n    \n    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(16, 8))\n    # Geting training history from results\n    history = results.history\n    # Ploting on first subplot\n    ax1.plot(history['loss'])\n    ax1.plot(history['val_loss'])\n    # Labeling \n    ax1.xaxis.set_label('Epochs')\n    ax1.yaxis.set_label('Loss')\n    ax1.legend(['loss', 'val_loss'])\n    # Ploting on second subplot\n    ax2.plot(history['acc'])\n    ax2.plot(history['val_acc'])\n    # Labeling \n    ax1.xaxis.set_label('Epochs')\n    ax1.yaxis.set_label('Accuracy')\n    ax2.legend(['Accuracy', 'Val_acc'])\n    fig.suptitle('Loss and Accuracy of Model')","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:58:54.172030Z","iopub.execute_input":"2021-11-18T22:58:54.172718Z","iopub.status.idle":"2021-11-18T22:58:54.180692Z","shell.execute_reply.started":"2021-11-18T22:58:54.172675Z","shell.execute_reply":"2021-11-18T22:58:54.179856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def oes_matrix(results):\n    \"\"\"\n    Plots a confusion matrix using the results atrribute of a Keras history object\n  \n    Parameters:\n    results (keras.callbacks.History): \n  \n    Returns:\n    None\n  \n    \"\"\"\n    conf = np.array([[results.history['true_negatives'][-1], results.history['false_negatives'][-1]], [results.history['false_positives'][-1], results.history['true_positives'][-1]]])\n    fig, ax = plt.subplots(figsize=(10, 8))\n    sns.heatmap(conf.astype('int'), annot=True, fmt='g', ax=ax )","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:46:18.531493Z","iopub.execute_input":"2021-11-18T23:46:18.531846Z","iopub.status.idle":"2021-11-18T23:46:18.538921Z","shell.execute_reply.started":"2021-11-18T23:46:18.531778Z","shell.execute_reply":"2021-11-18T23:46:18.538061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_results(baseline_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T22:58:54.182016Z","iopub.execute_input":"2021-11-18T22:58:54.182482Z","iopub.status.idle":"2021-11-18T22:58:54.758907Z","shell.execute_reply.started":"2021-11-18T22:58:54.182447Z","shell.execute_reply":"2021-11-18T22:58:54.757996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oes_matrix(baseline_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:46:20.887563Z","iopub.execute_input":"2021-11-18T23:46:20.887962Z","iopub.status.idle":"2021-11-18T23:46:21.189744Z","shell.execute_reply.started":"2021-11-18T23:46:20.887925Z","shell.execute_reply":"2021-11-18T23:46:21.189133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion**\n\nThis model is overfitting; training accuracy is around 95%, while testing data is at around 80%. Additionally, loss for testing data is oscillating too much.","metadata":{}},{"cell_type":"markdown","source":"### **Adding another layer to the baseline MLP**","metadata":{}},{"cell_type":"code","source":"# Setting up a two layer MLP\ntwo_hidden = keras.Sequential(\n    [\n        keras.Input(shape=(150,150,3)), # Don't always need this input separately\n        keras.layers.Flatten(), # need to flatten our images to be one long array\n        keras.layers.Dense(100, activation=\"relu\"),\n        keras.layers.Dense(50, activation=\"relu\"),\n        keras.layers.Dense(1, activation=\"sigmoid\"),\n    ])\n\ntwo_hidden.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:15:08.855823Z","iopub.execute_input":"2021-11-18T23:15:08.856252Z","iopub.status.idle":"2021-11-18T23:15:09.018758Z","shell.execute_reply.started":"2021-11-18T23:15:08.856197Z","shell.execute_reply":"2021-11-18T23:15:09.017649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compiling the two hidden layer MLP\ntwo_hidden.compile(optimizer='adam',\n                      loss='binary_crossentropy',\n                      metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:15:48.738867Z","iopub.execute_input":"2021-11-18T23:15:48.739172Z","iopub.status.idle":"2021-11-18T23:15:48.751172Z","shell.execute_reply.started":"2021-11-18T23:15:48.739140Z","shell.execute_reply":"2021-11-18T23:15:48.750095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the two hidden layer MLP\ntwo_hidden_results = two_hidden.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:16:36.122120Z","iopub.execute_input":"2021-11-18T23:16:36.122913Z","iopub.status.idle":"2021-11-18T23:21:57.781842Z","shell.execute_reply.started":"2021-11-18T23:16:36.122864Z","shell.execute_reply":"2021-11-18T23:21:57.781017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_results(two_hidden_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion**\n\nOnce again, the model is overfit. Also, judging from this graph showing the accuracy and loss for both training and validation data, it looks like it could benefit from a greater number of training epochs, since it looks like the validation loss might decrease further.","metadata":{}},{"cell_type":"markdown","source":"### **Adding Dropout layers to the two layer MLP**","metadata":{}},{"cell_type":"code","source":"two_hidden_dropout = keras.Sequential(\n    [\n        keras.Input(shape=(150,150,3)), # Don't always need this input separately\n        keras.layers.Flatten(), # need to flatten our images to be one long array\n        keras.layers.Dense(100, activation=\"relu\"),\n        keras.layers.Dropout(0.25),\n        keras.layers.Dense(50, activation=\"relu\"),\n        keras.layers.Dropout(0.25),\n        keras.layers.Dense(1, activation=\"sigmoid\"),\n    ])\n\ntwo_hidden_dropout.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:24:49.918019Z","iopub.execute_input":"2021-11-18T23:24:49.918322Z","iopub.status.idle":"2021-11-18T23:24:49.998867Z","shell.execute_reply.started":"2021-11-18T23:24:49.918290Z","shell.execute_reply":"2021-11-18T23:24:49.997875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compiling the two hidden layer dropout MLP\ntwo_hidden_dropout.compile(optimizer='adam',\n                      loss='binary_crossentropy',\n                      metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:24:56.239320Z","iopub.execute_input":"2021-11-18T23:24:56.239824Z","iopub.status.idle":"2021-11-18T23:24:56.249276Z","shell.execute_reply.started":"2021-11-18T23:24:56.239768Z","shell.execute_reply":"2021-11-18T23:24:56.248646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the two hidden layer dropout MLP\ntwo_hidden_dropout_results = two_hidden_dropout.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:25:02.350833Z","iopub.execute_input":"2021-11-18T23:25:02.351648Z","iopub.status.idle":"2021-11-18T23:30:12.498933Z","shell.execute_reply.started":"2021-11-18T23:25:02.351606Z","shell.execute_reply":"2021-11-18T23:30:12.497910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_results(two_hidden_dropout_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:30:12.501221Z","iopub.execute_input":"2021-11-18T23:30:12.501608Z","iopub.status.idle":"2021-11-18T23:30:13.089127Z","shell.execute_reply.started":"2021-11-18T23:30:12.501561Z","shell.execute_reply":"2021-11-18T23:30:13.088138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion**\n\nThis model requires improvement; test accuracy does not improve at all over the epochs, and testing loss is oscillating too frequently and with too great a magnitude.","metadata":{}},{"cell_type":"markdown","source":"## **Convolutional Neural Network (CNN) Model Iterations**\n\nThe MLP models we have run so far are a good start, but in order to get a network which really capture all of the detail of the images and can pick up on patterns, we need to run some CNNs.","metadata":{}},{"cell_type":"code","source":"# Create model\ndeep_cnn = keras.Sequential()\n\n# Adding first Conv2D and MaxPool layer, starting small and then growing larger.\ndeep_cnn.add(keras.layers.Conv2D(32, (2, 2), activation='relu', input_shape=(150, 150, 3)))\ndeep_cnn.add(keras.layers.MaxPool2D(2, 2))\n\n# Second layer with 64 filters\ndeep_cnn.add(keras.layers.Conv2D(64, (2, 2), activation='relu'))\ndeep_cnn.add(keras.layers.MaxPool2D(2, 2))\n\n# Third layer with 96 filters\ndeep_cnn.add(keras.layers.Conv2D(96, (2, 2), activation='relu'))\ndeep_cnn.add(keras.layers.MaxPool2D(2, 2))\n# Flatten layers, and add Densley connected layers for prediction\ndeep_cnn.add(keras.layers.Flatten())\n\n# Dense layer with 32 nodes\ndeep_cnn.add(keras.layers.Dense(32, activation='relu'))\n\n# Dense layer with 64 nodes\ndeep_cnn.add(keras.layers.Dense(64, activation='relu'))\n\n# Dense layer with 96 nodes\ndeep_cnn.add(keras.layers.Dense(96, activation='relu'))\n\n# Sigmoid output layer\ndeep_cnn.add(keras.layers.Dense(1, 'sigmoid'))\n\n\n#Compile model\ndeep_cnn.compile(\n    loss='binary_crossentropy',\n    optimizer='sgd',\n    # Adding additonal metrics for better monitoring of training.\n    metrics=['acc', 'Recall', 'Precision']\n    \n)\n\n# Fit Model to Training\ndeep_cnn_results = deep_cnn.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T00:35:34.080622Z","iopub.execute_input":"2021-11-19T00:35:34.080982Z","iopub.status.idle":"2021-11-19T00:44:07.192472Z","shell.execute_reply.started":"2021-11-19T00:35:34.080943Z","shell.execute_reply":"2021-11-19T00:44:07.191580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion**\n\nI added additional metrics on this model for more insights into the results of the training proccess. As far as performance goes it's definetly an improvement from the last model in terms of validation accuracy.\n\nSome other notes about the model:\n\n- The model is still overfitting\n- The validation accuracy is not conistently improving\n- Validation recall is very high, ~97% of true positives were identified correctly. This is good, since we decided that, in context of our buisness problem, false negatives are more costly then false positives.\n- Lets change the optimizer to see if this will improve the overfitting issues.","metadata":{}},{"cell_type":"markdown","source":"### **CNN model with added layers and Adam optimizer**","metadata":{}},{"cell_type":"code","source":"# Set up for this CNN model is from this blog:  https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\ncnn_adam = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_adam.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_adam.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_adam.add(layers.MaxPooling2D((2, 2)))\ncnn_adam.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_adam.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_adam.add(layers.MaxPooling2D((2, 2)))\ncnn_adam.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_adam.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_adam.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_adam.add(layers.Flatten())\ncnn_adam.add(layers.Dense(128, activation='relu'))\ncnn_adam.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_adam.compile(loss='binary_crossentropy',\n            optimizer=\"adam\",\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_adam_results = cnn_adam.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_results(cnn_adam_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusions**\n\nThis cnn models requires much improvement, because it is overfitting and as the training accuracy increases, the testing accuracy decreases, and as the training loss decreasesthe testing loss increases quite a lot. The double convolution layers before pooling may not be beneficial to increasing the model, so the convolution strategy will look more like the previous model in the next iteration.\n\nReading the keras documentation for adam optimizers, there was a note discussing how for some types of CNN models, the default value for the hyperparameter epsilon in adam (1e-7) may not be the best; they suggest trying bigger values such as 0.1 or 1. This was attempted in a notebook called \"Brooke Image Classification,\" but it was not beneficial to the ultimate progression of models, so it is not included here.","metadata":{}},{"cell_type":"markdown","source":"## **CNN with Dropout Layers, Early Stopping, and More Training**","metadata":{}},{"cell_type":"code","source":"# Create early stopping object\nearly_stopping = [\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n    keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5')\n]\n\n# Create model\nes_cnn = keras.Sequential()\n\n# Adding first Conv2D and MaxPool layer, starting small and then growing larger.\nes_cnn.add(keras.layers.Conv2D(32, (2, 2), activation='relu', input_shape=(150, 150, 3)))\nes_cnn.add(keras.layers.MaxPool2D(2, 2))\n\n# Second layer with 64 filters\nes_cnn.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\nes_cnn.add(keras.layers.MaxPool2D(3, 3))\n\n# Third layer with 96 filters\nes_cnn.add(keras.layers.Conv2D(96, (5, 5), activation='relu'))\nes_cnn.add(keras.layers.MaxPool2D(5, 5))\n# Flatten layers, and add Densley connected layers for prediction\nes_cnn.add(keras.layers.Flatten())\n\n# Dense layer with 32 nodes with dropout layer\nes_cnn.add(keras.layers.Dense(32, activation='relu'))\nes_cnn.add(keras.layers.Dropout(0.3))\n\n# Dense layer with 64 nodes with dropout layer\nes_cnn.add(keras.layers.Dense(64, activation='relu'))\nes_cnn.add(keras.layers.Dropout(0.3))\n\n# Dense layer with 96 nodes with dropout layer\nes_cnn.add(keras.layers.Dense(96, activation='relu'))\nes_cnn.add(keras.layers.Dropout(0.3))\n# Sigmoid output layer\nes_cnn.add(keras.layers.Dense(1, 'sigmoid'))\n\n#Compile model\nes_cnn.compile(\n    loss='binary_crossentropy',\n    optimizer='sgd',\n    # Adding additonal metrics for better monitoring of training.\n    metrics=['acc', 'Recall', 'Precision']\n    \n)\n\n# Fit Model to Training\nes_cnn_results = es_cnn.fit_generator(train_data,\n                              steps_per_epoch=150,\n                              epochs=25,\n                              validation_data=test_data,\n                              callbacks=early_stopping)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_results(es_cnn_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oes_matrix(visualize_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion**\n\nEarly stopping is working as intended, however, I've noticed that the first few epochs always have the same validation accuracy: 0.6250.\n\nThe model may be finding the local minimim instead of the global in these epochs. I'll try to tune the learning rate of my optimizer, and seeeing if that changes anything. I will also try to introduce class weights to the model, as that may help with the problem as well.","metadata":{}},{"cell_type":"code","source":"#### # Create model\nop_cnn = keras.Sequential()\n\n# Adding first Conv2D and MaxPool layer, starting small and then growing larger.\nop_cnn.add(keras.layers.Conv2D(32, (2, 2), activation='relu', input_shape=(150, 150, 3)))\nop_cnn.add(keras.layers.MaxPool2D(2, 2))\n\n# Second layer with 64 filters\nop_cnn.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\nop_cnn.add(keras.layers.MaxPool2D(3, 3))\n\n# Third layer with 96 filters\nop_cnn.add(keras.layers.Conv2D(96, (5, 5), activation='relu'))\nop_cnn.add(keras.layers.MaxPool2D(5, 5))\n# Flatten layers, and add Densley connected layers for prediction\nop_cnn.add(keras.layers.Flatten())\n\n# Dense layer with 32 nodes with dropout layer\nop_cnn.add(keras.layers.Dense(32, activation='relu'))\nop_cnn.add(keras.layers.Dropout(0.3))\n\n# Dense layer with 64 nodes with dropout layer\nop_cnn.add(keras.layers.Dense(64, activation='relu'))\nop_cnn.add(keras.layers.Dropout(0.3))\n\n# Dense layer with 96 nodes with dropout layer\nop_cnn.add(keras.layers.Dense(96, activation='relu'))\nop_cnn.add(keras.layers.Dropout(0.3))\n# Sigmoid output layer\nop_cnn.add(keras.layers.Dense(1, 'sigmoid'))\n\n# Create early stopping object\nop_early_stopping = [\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n    keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5')\n]\n# Create optimizer\noptim = SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n\n# Creating class weights\nweights = {\n    0: 2.88, # NORMAL\n    1: 1.    # PNEM\n}\n#Compile model\nop_cnn.compile(\n    loss='binary_crossentropy',\n    optimizer=optim,\n    # Adding additonal metrics for better monitoring of training.\n    metrics=['acc', 'Recall', 'Precision']\n    \n)\n\n# Fit Model to Training\nop_cnn_results = op_cnn.fit_generator(train_data,\n                              class_weight=weights,\n                              steps_per_epoch=50,\n                              epochs=100,\n                              validation_data=test_data,\n                              callbacks=op_early_stopping)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_results(op_cnn_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oes_matrix(op_cnn_results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion**\n\nThe early stopping worked great this time, and the changes to the optimizer, as well as adding class weights,has had a positive impact on the model. Validation accuracy is now sitting around ~87%. I'm going to add more layers and padding to the conv layers next, and see if that helps.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}