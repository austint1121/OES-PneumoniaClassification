{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# OES Data Preperation\n",
    "\n",
    "**Please read this notebook on [Kaggle](https://www.kaggle.com/matthewturnerirl/oes-data-prep/notebook)**\n",
    "\n",
    "\n",
    "The purpose of this notebook will demostrate and justify our data preperations steps used on our data. In our preperation we set up generators for our data, and in the generators we also re-scale and re-size the images before they are fed into our model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import statements\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport keras",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "scrolled": true,
    "execution": {
     "iopub.status.busy": "2021-11-16T21:03:54.341198Z",
     "iopub.execute_input": "2021-11-16T21:03:54.341486Z",
     "iopub.status.idle": "2021-11-16T21:03:54.346551Z",
     "shell.execute_reply.started": "2021-11-16T21:03:54.341456Z",
     "shell.execute_reply": "2021-11-16T21:03:54.345637Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Directory Setup\nDue to the large size of our dataset, we chose to use Kaggle as a place to store our data on the cloud. Our directory setup was structured in the following format: \n\n```\n├── chest-xray                    <- Top level directory\n│   ├── test                      <- Test set images\n│   │   ├── Normal                <- Normal lung photos      \n│   │   │   └── ...\n│   │   └──  Pneumonia            <- Pneumonia lung photos\n│   │   │   └── ...\n│   ├── train                     <- Training set images\n│   │   ├── Normal                <- Normal lung photos \n│   │   │   └── ...\n│   │   └──  Pneumonia            <- Pneumonia lung photos\n│   │   │   └── ...\n│   ├── val                       <- Training set images\n│   │   ├── Normal                <- Normal lung photos \n│   │   │   └── ...\n│   │   └──  Pneumonia            <- Pneumonia lung photos\n│   │   │   └── ...             \n\n```",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "This setup allows us to use Kera's Image Data Generator to load our data. We chose to use a generator for 3 reasons:\n- Saving memory and disk space by not downloading the dataset\n- Integrating the preproccesing into our modeling process\n- Easy re-sizing and rescaling of images\n\nUsing generators also allows more easily reproducable results. Since images fed into our model this way do not have to be preproccessed beforehand.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Instantiating a generator object and normalizing the RGB values\ntraingen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\ntestgen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\nvalgen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n\n# Creating the generator for the training data\ntrain_data = traingen.flow_from_directory(\n    # Specifying location of training data\n    directory='../input/chest-xray-pneumonia/chest_xray/train',\n    # Re-sizing images to 150x150\n    target_size=(150, 150),\n    # Class mode to binary to recoginize the two directories \"NORMAL\" and \"PNEUMONIA\" as the labels\n    class_mode='binary',\n    batch_size=20,\n    seed=42\n)\n# Creating the generator for the testing data\ntest_data = testgen.flow_from_directory(\n    # Specifying location of testing data\n    directory='../input/chest-xray-pneumonia/chest_xray/test',\n    # Re-sizing images to 150x150\n    target_size=(150, 150),\n    # Class mode to binary to recoginize the two directories \"NORMAL\" and \"PNEUMONIA\" as the labels\n    class_mode='binary',\n    batch_size=20,\n    seed=42\n)\n\n# Setting aside a validation set\nval_data = valgen.flow_from_directory(\n    # Specifying location of testing data\n    directory='../input/chest-xray-pneumonia/chest_xray/val',\n    # Re-sizing images to 150x150\n    target_size=(150, 150),\n    # Class mode to binary to recoginize the two directories \"NORMAL\" and \"PNEUMONIA\" as the labels\n    class_mode='binary',\n    batch_size=20,\n    seed=42\n)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-16T21:03:54.348290Z",
     "iopub.execute_input": "2021-11-16T21:03:54.348518Z",
     "iopub.status.idle": "2021-11-16T21:03:58.174117Z",
     "shell.execute_reply.started": "2021-11-16T21:03:54.348491Z",
     "shell.execute_reply": "2021-11-16T21:03:58.173196Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### Visualize Transformation\nWe will visualize the first 10 items in the training data set to check that all transformations to the images were done correctly.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visualize\ntrain_batch = train_data.next()\nfig, axes = plt.subplots(2, 5, figsize=(16, 8))\n    \nfor i in range(10):\n    # Load image into numpy array and re-scale\n    img = np.array(train_batch[0][i] * 255, dtype='uint8')\n    ax = axes[i // 5, i % 5]\n    ax.imshow(img)\nfig.suptitle('Training Images')\nplt.tight_layout()\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-11-16T21:03:58.175507Z",
     "iopub.execute_input": "2021-11-16T21:03:58.176147Z",
     "iopub.status.idle": "2021-11-16T21:04:00.073576Z",
     "shell.execute_reply.started": "2021-11-16T21:03:58.176096Z",
     "shell.execute_reply": "2021-11-16T21:04:00.072928Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Visual confirmation that the images are 150x150. We can now move on to the modeling phase.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}