{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","scrolled":true,"execution":{"iopub.status.busy":"2021-11-19T18:37:14.753835Z","iopub.execute_input":"2021-11-19T18:37:14.754053Z","iopub.status.idle":"2021-11-19T18:37:25.866055Z","shell.execute_reply.started":"2021-11-19T18:37:14.754027Z","shell.execute_reply":"2021-11-19T18:37:25.865317Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# General imports\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\nimport seaborn as sns\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.metrics import confusion_matrix\nimport cv2","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:38:49.258391Z","iopub.execute_input":"2021-11-19T18:38:49.258918Z","iopub.status.idle":"2021-11-19T18:38:49.264608Z","shell.execute_reply.started":"2021-11-19T18:38:49.258881Z","shell.execute_reply":"2021-11-19T18:38:49.263754Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# graphing of accuracy and loss from Lindsey's Neural\ndef visualize_training_results(history):\n    '''\n    From https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n    \n    Input: keras history object (output from trained model)\n    '''\n    fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n    fig.suptitle('Model Results')\n\n    # summarize history for accuracy\n    ax1.plot(history.history['acc'])\n    ax1.plot(history.history['val_acc'])\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['train', 'test'], loc='upper left')\n    # summarize history for loss\n    ax2.plot(history.history['loss'])\n    ax2.plot(history.history['val_loss'])\n    ax2.set_ylabel('Loss')\n    ax2.legend(['train', 'test'], loc='upper left')\n    \n    plt.xlabel('Epoch')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:37:31.651806Z","iopub.execute_input":"2021-11-19T18:37:31.652088Z","iopub.status.idle":"2021-11-19T18:37:31.661685Z","shell.execute_reply.started":"2021-11-19T18:37:31.652050Z","shell.execute_reply":"2021-11-19T18:37:31.661035Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**Business Problem:**\nMake a decision support tool for ER physicians looking at X_rays regarding lung issues for the first time","metadata":{}},{"cell_type":"markdown","source":"**Data Understanding**\n- Because we want to train a neural network to help identify whether or not a subject has pneumonia or not based on a chest X-ray, this dataset of 5,232 chest X-rays from children will help us train the network and so that it can be of use to doctors. There are 3,883 pneumonia x-rays and 1,349 normal ones, so there is a class imbalance issue. Additionally, each image is a different size, so it is necessary to standardize the images before modelling. \n- In the context of this data, a false positive would mean that the neural network identifies an x-ray as showing evidence of pneumonia, when it is really a normal x-ray. A false negative would mean that the neural network identifies a pneumonia image as being normal.","metadata":{}},{"cell_type":"markdown","source":"**Loading an Image, to see what it looks like**","metadata":{}},{"cell_type":"code","source":"import PIL","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:47.63001Z","iopub.execute_input":"2021-11-18T00:41:47.630375Z","iopub.status.idle":"2021-11-18T00:41:47.646207Z","shell.execute_reply.started":"2021-11-18T00:41:47.630338Z","shell.execute_reply":"2021-11-18T00:41:47.645444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = PIL.Image.open('../input/chest-xray-pneumonia/chest_xray/test/NORMAL/IM-0001-0001.jpeg')","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:47.649029Z","iopub.execute_input":"2021-11-18T00:41:47.6496Z","iopub.status.idle":"2021-11-18T00:41:47.672426Z","shell.execute_reply.started":"2021-11-18T00:41:47.649562Z","shell.execute_reply":"2021-11-18T00:41:47.671756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:47.673833Z","iopub.execute_input":"2021-11-18T00:41:47.674092Z","iopub.status.idle":"2021-11-18T00:41:48.248186Z","shell.execute_reply.started":"2021-11-18T00:41:47.674056Z","shell.execute_reply":"2021-11-18T00:41:48.247459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image.size","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:48.249413Z","iopub.execute_input":"2021-11-18T00:41:48.250112Z","iopub.status.idle":"2021-11-18T00:41:48.256765Z","shell.execute_reply.started":"2021-11-18T00:41:48.250069Z","shell.execute_reply":"2021-11-18T00:41:48.255853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Setting up a Generator to Load and Reshape Images**","metadata":{}},{"cell_type":"code","source":"# Your code here; transform the image files and then load them into Keras as tensors \n# (be sure to perform a train-val-test split)\nimport keras\n\n# Instantiating a generator object and normalizing the RGB values\ntraingen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\ntestgen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\nvalgen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n\ntrain_data = traingen.flow_from_directory(\n    directory='../input/chest-xray-pneumonia/chest_xray/train',\n    target_size=(150, 150),\n    class_mode='binary',\n    batch_size=20,\n    shuffle=True,\n    seed=42\n)\ntrain_labels = []\nbatch_index1 = 0\n\n#while batch_index1 <= train_data.batch_index:\n    #x1, y1 = train_data.next()\n    #for i in range(len(y1)):\n        #train_labels.extend(y1)\n    #batch_index1 = batch_index1 + 1\n\n\ntest_data = testgen.flow_from_directory(\n    directory='../input/chest-xray-pneumonia/chest_xray/test',\n    target_size=(150, 150),\n    class_mode='binary',\n    batch_size=20,\n    shuffle=True,\n    seed=42\n)\n#test_labels = []\n#batch_index2 = 0\n\n#while batch_index2 <= test_data.batch_index:\n    #x2, y2 = test_data.next()\n    #for i in range(len(y2)):\n        #test_labels.extend(y2)\n    #batch_index2 = batch_index2 + 1\n\nval_data = valgen.flow_from_directory(\n    directory='../input/chest-xray-pneumonia/chest_xray/val',\n    target_size=(150, 150),\n    class_mode='binary',\n    batch_size=20,\n    shuffle=True,\n    seed=42\n)\n#val_labels = []\n#batch_index3 = 0\n\n#while batch_index3 <= val_data.batch_index:\n    #x3, y3 = val_data.next()\n    #for i in range(len(y3)):\n        #val_labels.extend(y3)\n    #batch_index3 = batch_index3 + 1","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:37:47.732131Z","iopub.execute_input":"2021-11-19T18:37:47.732392Z","iopub.status.idle":"2021-11-19T18:37:48.930754Z","shell.execute_reply.started":"2021-11-19T18:37:47.732363Z","shell.execute_reply":"2021-11-19T18:37:48.929992Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# from https://www.kaggle.com/madz2000/pneumonia-detection-using-cnn-92-6-accuracy#Loading-the-Dataset\nlabels = ['PNEUMONIA', 'NORMAL']\nimg_size = 150\ndef get_training_data(data_dir):\n    data = [] \n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n                data.append([resized_arr, class_num])\n            except Exception as e:\n                print(e)\n    return np.array(data)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T17:58:24.377832Z","iopub.execute_input":"2021-11-19T17:58:24.378542Z","iopub.status.idle":"2021-11-19T17:58:24.385330Z","shell.execute_reply.started":"2021-11-19T17:58:24.378488Z","shell.execute_reply":"2021-11-19T17:58:24.384353Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"training = get_training_data('../input/chest-xray-pneumonia/chest_xray/train')\ntesting = get_training_data('../input/chest-xray-pneumonia/chest_xray/test')\nvalidating = get_training_data('../input/chest-xray-pneumonia/chest_xray/val')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-18T20:23:36.064396Z","iopub.execute_input":"2021-11-18T20:23:36.064669Z","iopub.status.idle":"2021-11-18T20:24:24.428311Z","shell.execute_reply.started":"2021-11-18T20:23:36.06462Z","shell.execute_reply":"2021-11-18T20:24:24.427564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training[0][1]","metadata":{"execution":{"iopub.status.busy":"2021-11-18T20:59:50.51676Z","iopub.execute_input":"2021-11-18T20:59:50.517016Z","iopub.status.idle":"2021-11-18T20:59:50.523243Z","shell.execute_reply.started":"2021-11-18T20:59:50.516988Z","shell.execute_reply":"2021-11-18T20:59:50.522528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_labels = []\nfor x, y in training:\n    training_labels.append(y)\nlen(training_labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T20:24:47.038099Z","iopub.execute_input":"2021-11-18T20:24:47.039022Z","iopub.status.idle":"2021-11-18T20:24:47.054737Z","shell.execute_reply.started":"2021-11-18T20:24:47.038947Z","shell.execute_reply":"2021-11-18T20:24:47.054054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testing_labels2 = []\nfor x, y in testing:\n    testing_labels2.append(y)\nlen(testing_labels2)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T20:27:30.314484Z","iopub.execute_input":"2021-11-18T20:27:30.315178Z","iopub.status.idle":"2021-11-18T20:27:30.322552Z","shell.execute_reply.started":"2021-11-18T20:27:30.31514Z","shell.execute_reply":"2021-11-18T20:27:30.321844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validating_labels = []\nfor x, y in validating:\n    validating_labels.append(y)\nlen(validating_labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T20:28:31.093878Z","iopub.execute_input":"2021-11-18T20:28:31.094132Z","iopub.status.idle":"2021-11-18T20:28:31.101156Z","shell.execute_reply.started":"2021-11-18T20:28:31.094104Z","shell.execute_reply":"2021-11-18T20:28:31.100488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**EDA**","metadata":{}},{"cell_type":"code","source":"(train_data.class_indices)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:49.582308Z","iopub.execute_input":"2021-11-18T00:41:49.582725Z","iopub.status.idle":"2021-11-18T00:41:49.589426Z","shell.execute_reply.started":"2021-11-18T00:41:49.582664Z","shell.execute_reply":"2021-11-18T00:41:49.588334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = pd.DataFrame(train_data.classes)\nvalues = classes.value_counts()\nclass_dict = {0:'Normal', 1:'Pneumonia'}","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:49.591155Z","iopub.execute_input":"2021-11-18T00:41:49.592174Z","iopub.status.idle":"2021-11-18T00:41:49.607493Z","shell.execute_reply.started":"2021-11-18T00:41:49.592112Z","shell.execute_reply":"2021-11-18T00:41:49.606752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes[0] = classes[0].map(class_dict)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:49.608932Z","iopub.execute_input":"2021-11-18T00:41:49.60933Z","iopub.status.idle":"2021-11-18T00:41:49.61899Z","shell.execute_reply.started":"2021-11-18T00:41:49.609292Z","shell.execute_reply":"2021-11-18T00:41:49.618186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"diag = classes[0].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:41:49.62197Z","iopub.execute_input":"2021-11-18T00:41:49.622678Z","iopub.status.idle":"2021-11-18T00:41:49.628045Z","shell.execute_reply.started":"2021-11-18T00:41:49.622645Z","shell.execute_reply":"2021-11-18T00:41:49.627105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.set(font_scale=1.4)\nsns.barplot(diag.index, diag.values)\nplt.ylabel(\"Number of Images\")\nplt.title('Distribution of Chest X-ray Images');","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:45:10.835363Z","iopub.execute_input":"2021-11-18T00:45:10.835615Z","iopub.status.idle":"2021-11-18T00:45:11.067596Z","shell.execute_reply.started":"2021-11-18T00:45:10.835587Z","shell.execute_reply":"2021-11-18T00:45:11.065757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Baseline Model**","metadata":{}},{"cell_type":"code","source":"\n#baseline_model = keras.Sequential(name='dense')\n#baseline_model.add(Dense(500, activation='relu', input_shape=(150,150, 3))\n#baseline_model.add(Dense(250, activation='relu'))\n#baseline_model.add(Dense(1, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:50:20.077767Z","iopub.execute_input":"2021-11-18T00:50:20.078045Z","iopub.status.idle":"2021-11-18T00:50:20.081384Z","shell.execute_reply.started":"2021-11-18T00:50:20.078016Z","shell.execute_reply":"2021-11-18T00:50:20.08056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input shape to be used in all models\ninput_shape = (150,150,3)\noutput_shape = 1","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:37:55.727508Z","iopub.execute_input":"2021-11-19T18:37:55.727762Z","iopub.status.idle":"2021-11-19T18:37:55.732852Z","shell.execute_reply.started":"2021-11-19T18:37:55.727732Z","shell.execute_reply":"2021-11-19T18:37:55.732090Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"baseline = keras.Sequential(\n    [\n        keras.Input(shape=input_shape), # Don't always need this input separately\n        layers.Flatten(), # need to flatten our images to be one long array\n        layers.Dense(100, activation=\"relu\"),\n        layers.Dense(output_shape, activation=\"sigmoid\"),\n    ])\n\nbaseline.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:38:20.976894Z","iopub.execute_input":"2021-11-19T18:38:20.977232Z","iopub.status.idle":"2021-11-19T18:38:23.392752Z","shell.execute_reply.started":"2021-11-19T18:38:20.977190Z","shell.execute_reply":"2021-11-19T18:38:23.392020Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"baseline.compile(optimizer='adam',\n                      loss='binary_crossentropy',\n                      metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:50:22.518022Z","iopub.execute_input":"2021-11-18T00:50:22.518479Z","iopub.status.idle":"2021-11-18T00:50:22.530633Z","shell.execute_reply.started":"2021-11-18T00:50:22.518438Z","shell.execute_reply":"2021-11-18T00:50:22.52984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nbaseline_results = baseline.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data,)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:50:22.533657Z","iopub.execute_input":"2021-11-18T00:50:22.534356Z","iopub.status.idle":"2021-11-18T00:57:25.831261Z","shell.execute_reply.started":"2021-11-18T00:50:22.534313Z","shell.execute_reply":"2021-11-18T00:57:25.830518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_results.history","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:57:25.832786Z","iopub.execute_input":"2021-11-18T00:57:25.83331Z","iopub.status.idle":"2021-11-18T00:57:25.840184Z","shell.execute_reply.started":"2021-11-18T00:57:25.833269Z","shell.execute_reply":"2021-11-18T00:57:25.839465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(baseline_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:57:25.841748Z","iopub.execute_input":"2021-11-18T00:57:25.842241Z","iopub.status.idle":"2021-11-18T00:57:26.17316Z","shell.execute_reply.started":"2021-11-18T00:57:25.842204Z","shell.execute_reply":"2021-11-18T00:57:26.172392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model is definitely overfit, because the accuracy in training data is much higher than that of the validation data. This is a very simple neural network, and so it could benefit from adding another layer to learn patterns from. This might also help decrease loss.","metadata":{}},{"cell_type":"markdown","source":"**Adding another layer**","metadata":{}},{"cell_type":"code","source":"# Adding in the layers\ntwo_hidden = keras.Sequential(\n    [\n        keras.Input(shape=input_shape), # Don't always need this input separately\n        layers.Flatten(), # need to flatten our images to be one long array\n        layers.Dense(100, activation='relu'),\n        layers.Dense(50, activation='relu'),\n        layers.Dense(output_shape, activation=\"sigmoid\"),\n    ])\n\ntwo_hidden.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:57:26.1744Z","iopub.execute_input":"2021-11-18T00:57:26.17685Z","iopub.status.idle":"2021-11-18T00:57:26.214648Z","shell.execute_reply.started":"2021-11-18T00:57:26.176808Z","shell.execute_reply":"2021-11-18T00:57:26.213937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compiling the two-layer model\ntwo_hidden.compile(optimizer='adam',\n                      loss='binary_crossentropy',\n                      metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:57:26.215807Z","iopub.execute_input":"2021-11-18T00:57:26.216061Z","iopub.status.idle":"2021-11-18T00:57:26.227173Z","shell.execute_reply.started":"2021-11-18T00:57:26.216025Z","shell.execute_reply":"2021-11-18T00:57:26.226435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the two-layer model \ntwo_hidden_results = two_hidden.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T00:57:26.228944Z","iopub.execute_input":"2021-11-18T00:57:26.229234Z","iopub.status.idle":"2021-11-18T01:03:13.238939Z","shell.execute_reply.started":"2021-11-18T00:57:26.229198Z","shell.execute_reply":"2021-11-18T01:03:13.23802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(two_hidden_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:03:13.242004Z","iopub.execute_input":"2021-11-18T01:03:13.24251Z","iopub.status.idle":"2021-11-18T01:03:13.584292Z","shell.execute_reply.started":"2021-11-18T01:03:13.242466Z","shell.execute_reply":"2021-11-18T01:03:13.583544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once again, the model is overfit. Also, judging from this graph showing the accuracy and loss for both training and validation data, it looks like it could benefit from a greater number of training epochs, since it looks like the validation loss might decrease further.","metadata":{}},{"cell_type":"markdown","source":"**Double the number of epochs**","metadata":{}},{"cell_type":"code","source":"# Adding in the layers\nmore_epochs = keras.Sequential(\n    [\n        keras.Input(shape=input_shape), # Don't always need this input separately\n        layers.Flatten(), # need to flatten our images to be one long array\n        layers.Dense(100, activation='relu'),\n        layers.Dense(50, activation='relu'),\n        layers.Dense(output_shape, activation=\"sigmoid\"),\n    ])\n\nmore_epochs.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:03:13.58584Z","iopub.execute_input":"2021-11-18T01:03:13.586326Z","iopub.status.idle":"2021-11-18T01:03:13.624069Z","shell.execute_reply.started":"2021-11-18T01:03:13.586287Z","shell.execute_reply":"2021-11-18T01:03:13.62336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compiling the two-layer model\nmore_epochs.compile(optimizer='adam',\n                      loss='binary_crossentropy',\n                      metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:03:13.625273Z","iopub.execute_input":"2021-11-18T01:03:13.625609Z","iopub.status.idle":"2021-11-18T01:03:13.635469Z","shell.execute_reply.started":"2021-11-18T01:03:13.625571Z","shell.execute_reply":"2021-11-18T01:03:13.63452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit the two-layer model \nmore_epochs_results = more_epochs.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=30,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:03:13.640642Z","iopub.execute_input":"2021-11-18T01:03:13.640867Z","iopub.status.idle":"2021-11-18T01:22:42.814775Z","shell.execute_reply.started":"2021-11-18T01:03:13.640842Z","shell.execute_reply":"2021-11-18T01:22:42.81398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(more_epochs_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T01:22:42.816372Z","iopub.execute_input":"2021-11-18T01:22:42.816632Z","iopub.status.idle":"2021-11-18T01:22:43.357931Z","shell.execute_reply.started":"2021-11-18T01:22:42.816594Z","shell.execute_reply":"2021-11-18T01:22:43.357136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once again, the model is overfitting. It also looks like the loss is oscillating a good deal, but not necessarily decreasing. It is probably time to try a Convolutional model, especially since this is an image classification problem. Adding convolutions will put filters on the images to help the model pick up on patterns better.","metadata":{}},{"cell_type":"markdown","source":"**Building a Convolutional Neural Network**","metadata":{}},{"cell_type":"code","source":"# Set up for this CNN model is from this blog:  https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\ncnn = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn.add(layers.MaxPooling2D((2, 2)))\ncnn.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn.add(layers.MaxPooling2D((2, 2)))\ncnn.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn.add(layers.Flatten())\ncnn.add(layers.Dense(128, activation='relu'))\ncnn.add(layers.Dense(1, activation='sigmoid'))\n\ncnn.compile(loss='binary_crossentropy',\n            optimizer=\"adam\",\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T04:18:40.388748Z","iopub.execute_input":"2021-11-18T04:18:40.389054Z","iopub.status.idle":"2021-11-18T04:18:40.548645Z","shell.execute_reply.started":"2021-11-18T04:18:40.38902Z","shell.execute_reply":"2021-11-18T04:18:40.54762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T04:18:44.982067Z","iopub.execute_input":"2021-11-18T04:18:44.982387Z","iopub.status.idle":"2021-11-18T04:18:45.001435Z","shell.execute_reply.started":"2021-11-18T04:18:44.982343Z","shell.execute_reply":"2021-11-18T04:18:45.000482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_results = cnn.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T04:18:47.783186Z","iopub.execute_input":"2021-11-18T04:18:47.783817Z","iopub.status.idle":"2021-11-18T04:25:51.252942Z","shell.execute_reply.started":"2021-11-18T04:18:47.78378Z","shell.execute_reply":"2021-11-18T04:25:51.251981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T04:27:20.890858Z","iopub.execute_input":"2021-11-18T04:27:20.891213Z","iopub.status.idle":"2021-11-18T04:27:21.256035Z","shell.execute_reply.started":"2021-11-18T04:27:20.891171Z","shell.execute_reply":"2021-11-18T04:27:21.255056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This cnn models requires much improvement, because it is overfitting and as the training accuracy increases, the testing accuracy decreases, and as the training loss decreasesthe testing loss increases quite a lot.\nReading the keras documentation for adam optimizers, there was a note discussing how for some types of CNN models, the default value for the hyperparameter epsilon in adam (1e-7) may not be the best; they suggest trying bigger values such as 0.1 or 1, so I will try this in the next model.","metadata":{}},{"cell_type":"markdown","source":"**CNN with a bigger epsilon (0.1)**","metadata":{}},{"cell_type":"code","source":"adam_ep = keras.optimizers.Adam(epsilon=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:39:27.007747Z","iopub.execute_input":"2021-11-19T18:39:27.008066Z","iopub.status.idle":"2021-11-19T18:39:27.012953Z","shell.execute_reply.started":"2021-11-19T18:39:27.008022Z","shell.execute_reply":"2021-11-19T18:39:27.012104Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_ep = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_ep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_ep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_ep.add(layers.MaxPooling2D((2, 2)))\ncnn_ep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_ep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_ep.add(layers.MaxPooling2D((2, 2)))\ncnn_ep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_ep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_ep.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_ep.add(layers.Flatten())\ncnn_ep.add(layers.Dense(128, activation='relu'))\ncnn_ep.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_ep.compile(loss='binary_crossentropy',\n            optimizer= adam_ep,\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:52:43.592426Z","iopub.execute_input":"2021-11-19T19:52:43.592689Z","iopub.status.idle":"2021-11-19T19:52:43.675766Z","shell.execute_reply.started":"2021-11-19T19:52:43.592660Z","shell.execute_reply":"2021-11-19T19:52:43.675084Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"cnn_ep_results = cnn_ep.fit_generator(train_data,\n                              steps_per_epoch=50,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:52:59.766503Z","iopub.execute_input":"2021-11-19T19:52:59.767104Z","iopub.status.idle":"2021-11-19T19:56:20.458873Z","shell.execute_reply.started":"2021-11-19T19:52:59.767062Z","shell.execute_reply":"2021-11-19T19:56:20.458107Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_ep_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:56:20.740350Z","iopub.execute_input":"2021-11-19T19:56:20.740606Z","iopub.status.idle":"2021-11-19T19:56:21.018947Z","shell.execute_reply.started":"2021-11-19T19:56:20.740559Z","shell.execute_reply":"2021-11-19T19:56:21.018284Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"Increasing the epsilon value seems to reduce the validation data loss, and to increase the validation data accuracy. It also seems to reduce some of the overfitting that was taking place in previous models. It would also be interesting to see what changing the learning rate does to the model.","metadata":{}},{"cell_type":"markdown","source":"**CNN with a bigger epsilon (0.1) and smaller learning rate (0.0001)**","metadata":{}},{"cell_type":"code","source":"adam_lep = keras.optimizers.Adam(learning_rate=0.0001, epsilon=0.1)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:39:09.121336Z","iopub.execute_input":"2021-11-19T18:39:09.121779Z","iopub.status.idle":"2021-11-19T18:39:09.125728Z","shell.execute_reply.started":"2021-11-19T18:39:09.121741Z","shell.execute_reply":"2021-11-19T18:39:09.124822Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_lep = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_lep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_lep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_lep.add(layers.MaxPooling2D((2, 2)))\ncnn_lep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_lep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_lep.add(layers.MaxPooling2D((2, 2)))\ncnn_lep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_lep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_lep.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_lep.add(layers.Flatten())\ncnn_lep.add(layers.Dense(128, activation='relu'))\ncnn_lep.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_lep.compile(loss='binary_crossentropy',\n            optimizer= adam_lep,\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T21:33:46.627056Z","iopub.execute_input":"2021-11-18T21:33:46.627313Z","iopub.status.idle":"2021-11-18T21:33:46.713612Z","shell.execute_reply.started":"2021-11-18T21:33:46.627286Z","shell.execute_reply":"2021-11-18T21:33:46.712933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_lep_results = cnn_lep.fit_generator(train_data,\n                              steps_per_epoch=50,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T21:33:51.990967Z","iopub.execute_input":"2021-11-18T21:33:51.993706Z","iopub.status.idle":"2021-11-18T21:36:45.400654Z","shell.execute_reply.started":"2021-11-18T21:33:51.993667Z","shell.execute_reply":"2021-11-18T21:36:45.399952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_lep_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T21:36:50.329645Z","iopub.execute_input":"2021-11-18T21:36:50.330177Z","iopub.status.idle":"2021-11-18T21:36:50.630768Z","shell.execute_reply.started":"2021-11-18T21:36:50.330143Z","shell.execute_reply":"2021-11-18T21:36:50.630128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Decreasing the learning rate did not have a good effect on the model; it is clearly still overfitting and the testing accuracy ","metadata":{}},{"cell_type":"markdown","source":"**CNN with changed epsilon and L2 regularization**","metadata":{}},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_rep = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_rep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_rep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_rep.add(layers.MaxPooling2D((2, 2)))\ncnn_rep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_rep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_rep.add(layers.MaxPooling2D((2, 2)))\ncnn_rep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_rep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_rep.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_rep.add(layers.Flatten())\ncnn_rep.add(layers.Dense(128, kernel_regularizer= regularizers.l2(0.01), activation='relu'))\ncnn_rep.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_rep.compile(loss='binary_crossentropy',\n            optimizer= adam_ep,\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:39:34.529871Z","iopub.execute_input":"2021-11-19T18:39:34.530643Z","iopub.status.idle":"2021-11-19T18:39:34.640699Z","shell.execute_reply.started":"2021-11-19T18:39:34.530602Z","shell.execute_reply":"2021-11-19T18:39:34.639920Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"cnn_rep = cnn_rep.fit_generator(train_data,\n                              steps_per_epoch=50,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:39:40.187734Z","iopub.execute_input":"2021-11-19T18:39:40.188288Z","iopub.status.idle":"2021-11-19T18:43:19.549920Z","shell.execute_reply.started":"2021-11-19T18:39:40.188248Z","shell.execute_reply":"2021-11-19T18:43:19.549198Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_rep)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:43:49.373212Z","iopub.execute_input":"2021-11-19T18:43:49.373780Z","iopub.status.idle":"2021-11-19T18:43:49.686858Z","shell.execute_reply.started":"2021-11-19T18:43:49.373740Z","shell.execute_reply":"2021-11-19T18:43:49.686161Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Using regularization decreased the overfitting problem and also helped to decrease the loss in both training and testing data; however, there is still a good deal of loss going on, so further iterations are needed to decrease this loss. To see if L1 regularization will decrease the loss, I will try this next.","metadata":{}},{"cell_type":"markdown","source":"**CNN with changed epsilon and L1 regularization**","metadata":{}},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_r1ep = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_r1ep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_r1ep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_r1ep.add(layers.MaxPooling2D((2, 2)))\ncnn_r1ep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_r1ep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_r1ep.add(layers.MaxPooling2D((2, 2)))\ncnn_r1ep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_r1ep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_r1ep.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_r1ep.add(layers.Flatten())\ncnn_r1ep.add(layers.Dense(128, kernel_regularizer= regularizers.l1(0.01), activation='relu'))\ncnn_r1ep.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_r1ep.compile(loss='binary_crossentropy',\n            optimizer= adam_ep,\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:45:06.144875Z","iopub.execute_input":"2021-11-19T18:45:06.145578Z","iopub.status.idle":"2021-11-19T18:45:06.231836Z","shell.execute_reply.started":"2021-11-19T18:45:06.145531Z","shell.execute_reply":"2021-11-19T18:45:06.231119Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"cnn_r1ep = cnn_r1ep.fit_generator(train_data,\n                              steps_per_epoch=50,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:45:22.771286Z","iopub.execute_input":"2021-11-19T18:45:22.771540Z","iopub.status.idle":"2021-11-19T18:48:37.667477Z","shell.execute_reply.started":"2021-11-19T18:45:22.771513Z","shell.execute_reply":"2021-11-19T18:48:37.666737Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_r1ep)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:51:22.090884Z","iopub.execute_input":"2021-11-19T18:51:22.091496Z","iopub.status.idle":"2021-11-19T18:51:22.371024Z","shell.execute_reply.started":"2021-11-19T18:51:22.091459Z","shell.execute_reply":"2021-11-19T18:51:22.370325Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"L1 Regularization caused the model to perform much worse than when L2 was used; accuracy is less and loss is more, and there is a big overfitting problem. Even though L2 regularization looks like it may be beneficial, for now I am going to take out all regularization in order to more clearly see the difference which results from adding another layer, in the next model iteration.","metadata":{}},{"cell_type":"markdown","source":"**CNN model with changed epsilon and added Dense layer**","metadata":{}},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_dep = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_dep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_dep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_dep.add(layers.MaxPooling2D((2, 2)))\ncnn_dep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_dep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_dep.add(layers.MaxPooling2D((2, 2)))\ncnn_dep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_dep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_dep.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_dep.add(layers.Flatten())\ncnn_dep.add(layers.Dense(128, activation='relu'))\ncnn_dep.add(layers.Dense(64, activation='relu'))\ncnn_dep.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_dep.compile(loss='binary_crossentropy',\n            optimizer= adam_ep,\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:51:35.012366Z","iopub.execute_input":"2021-11-19T18:51:35.012923Z","iopub.status.idle":"2021-11-19T18:51:35.103004Z","shell.execute_reply.started":"2021-11-19T18:51:35.012884Z","shell.execute_reply":"2021-11-19T18:51:35.102334Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"cnn_dep = cnn_dep.fit_generator(train_data,\n                              steps_per_epoch=50,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T18:51:38.586806Z","iopub.execute_input":"2021-11-19T18:51:38.587548Z","iopub.status.idle":"2021-11-19T18:54:59.492390Z","shell.execute_reply.started":"2021-11-19T18:51:38.587510Z","shell.execute_reply":"2021-11-19T18:54:59.491468Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_dep)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:04:10.149549Z","iopub.execute_input":"2021-11-19T19:04:10.149828Z","iopub.status.idle":"2021-11-19T19:04:10.437519Z","shell.execute_reply.started":"2021-11-19T19:04:10.149796Z","shell.execute_reply":"2021-11-19T19:04:10.436824Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"The results of accuracy and loss for training and testing data is not much different than the CNN model with changed epsilon and one layer. However, maybe adding dropout layers will improve the results.","metadata":{}},{"cell_type":"markdown","source":"**CNN model with changed epsilon, added layer, and dropout layers**","metadata":{}},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_ddep = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_ddep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_ddep.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_ddep.add(layers.MaxPooling2D((2, 2)))\ncnn_ddep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_ddep.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_ddep.add(layers.MaxPooling2D((2, 2)))\ncnn_ddep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_ddep.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_ddep.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_ddep.add(layers.Flatten())\ncnn_ddep.add(layers.Dense(128, activation='relu'))\ncnn_ddep.add(layers.Dropout(0.25))\ncnn_ddep.add(layers.Dense(64, activation='relu'))\ncnn_ddep.add(layers.Dropout(0.25))\ncnn_ddep.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_ddep.compile(loss='binary_crossentropy',\n            optimizer= adam_ep,\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:04:14.406656Z","iopub.execute_input":"2021-11-19T19:04:14.407361Z","iopub.status.idle":"2021-11-19T19:04:14.503195Z","shell.execute_reply.started":"2021-11-19T19:04:14.407324Z","shell.execute_reply":"2021-11-19T19:04:14.502486Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"cnn_ddep = cnn_ddep.fit_generator(train_data,\n                              steps_per_epoch=50,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:04:18.568168Z","iopub.execute_input":"2021-11-19T19:04:18.569335Z","iopub.status.idle":"2021-11-19T19:07:28.439150Z","shell.execute_reply.started":"2021-11-19T19:04:18.569286Z","shell.execute_reply":"2021-11-19T19:07:28.438373Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_ddep)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:11:40.566487Z","iopub.execute_input":"2021-11-19T19:11:40.566760Z","iopub.status.idle":"2021-11-19T19:11:40.836627Z","shell.execute_reply.started":"2021-11-19T19:11:40.566731Z","shell.execute_reply":"2021-11-19T19:11:40.835872Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"The main thing that is different about this model is that the loss is higher for training and testing data. In the next iteration, I will try using a normal epsilon to see if this works better with multiple layers and dropout layers.","metadata":{}},{"cell_type":"markdown","source":"**CNN model with normal epsilon, added layers, added Dropout layers**","metadata":{}},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_dd = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_dd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_dd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_dd.add(layers.MaxPooling2D((2, 2)))\ncnn_dd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_dd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_dd.add(layers.MaxPooling2D((2, 2)))\ncnn_dd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_dd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_dd.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_dd.add(layers.Flatten())\ncnn_dd.add(layers.Dense(128, activation='relu'))\ncnn_dd.add(layers.Dropout(0.25))\ncnn_dd.add(layers.Dense(64, activation='relu'))\ncnn_dd.add(layers.Dropout(0.25))\ncnn_dd.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_dd.compile(loss='binary_crossentropy',\n            optimizer= 'adam',\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:11:54.918803Z","iopub.execute_input":"2021-11-19T19:11:54.919353Z","iopub.status.idle":"2021-11-19T19:11:55.015426Z","shell.execute_reply.started":"2021-11-19T19:11:54.919315Z","shell.execute_reply":"2021-11-19T19:11:55.014733Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"cnn_dd = cnn_dd.fit_generator(train_data,\n                              steps_per_epoch=50,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:11:58.243488Z","iopub.execute_input":"2021-11-19T19:11:58.243971Z","iopub.status.idle":"2021-11-19T19:15:07.203112Z","shell.execute_reply.started":"2021-11-19T19:11:58.243907Z","shell.execute_reply":"2021-11-19T19:15:07.202284Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_dd)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:17:38.358736Z","iopub.execute_input":"2021-11-19T19:17:38.359104Z","iopub.status.idle":"2021-11-19T19:17:38.646475Z","shell.execute_reply.started":"2021-11-19T19:17:38.359071Z","shell.execute_reply":"2021-11-19T19:17:38.645787Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"There is a bigger overfitting problem with this model than in the last iteration; maybe having a bigger epsilon (0.1) is better. Or perhaps using a different optimizer would improve results; will try SGD in next model iteration.","metadata":{}},{"cell_type":"markdown","source":"**CNN model with SGD, normal epsilon, added layers, added Dropout layers**","metadata":{}},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_sdd = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_sdd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_sdd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_sdd.add(layers.MaxPooling2D((2, 2)))\ncnn_sdd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_sdd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_sdd.add(layers.MaxPooling2D((2, 2)))\ncnn_sdd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_sdd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_sdd.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_sdd.add(layers.Flatten())\ncnn_sdd.add(layers.Dense(128, activation='relu'))\ncnn_sdd.add(layers.Dropout(0.25))\ncnn_sdd.add(layers.Dense(64, activation='relu'))\ncnn_sdd.add(layers.Dropout(0.25))\ncnn_sdd.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_sdd.compile(loss='binary_crossentropy',\n            optimizer= 'sgd',\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:17:41.844107Z","iopub.execute_input":"2021-11-19T19:17:41.844753Z","iopub.status.idle":"2021-11-19T19:17:41.961247Z","shell.execute_reply.started":"2021-11-19T19:17:41.844704Z","shell.execute_reply":"2021-11-19T19:17:41.960537Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"cnn_sdd = cnn_sdd.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:17:45.342695Z","iopub.execute_input":"2021-11-19T19:17:45.342954Z","iopub.status.idle":"2021-11-19T19:24:03.924850Z","shell.execute_reply.started":"2021-11-19T19:17:45.342924Z","shell.execute_reply":"2021-11-19T19:24:03.924019Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_sdd)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:33:40.482102Z","iopub.execute_input":"2021-11-19T19:33:40.482889Z","iopub.status.idle":"2021-11-19T19:33:40.773493Z","shell.execute_reply.started":"2021-11-19T19:33:40.482840Z","shell.execute_reply":"2021-11-19T19:33:40.772824Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"Changing to SGD optimizer resulted in a very big difference between the loss in training and test data. Will try seeing if having a greater number of epochs will help decrease loss.","metadata":{}},{"cell_type":"markdown","source":"**CNN model with fewer steps per epoch, more epochs, SGD, normal epsilon, added layers, added Dropout layers**","metadata":{}},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_smdd = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_smdd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_smdd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_smdd.add(layers.MaxPooling2D((2, 2)))\ncnn_smdd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_smdd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_smdd.add(layers.MaxPooling2D((2, 2)))\ncnn_smdd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_smdd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_smdd.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_smdd.add(layers.Flatten())\ncnn_smdd.add(layers.Dense(128, activation='relu'))\ncnn_smdd.add(layers.Dropout(0.25))\ncnn_smdd.add(layers.Dense(64, activation='relu'))\ncnn_smdd.add(layers.Dropout(0.25))\ncnn_smdd.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_smdd.compile(loss='binary_crossentropy',\n            optimizer= 'sgd',\n            metrics=['acc', 'Recall', 'Precision','TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:33:44.782810Z","iopub.execute_input":"2021-11-19T19:33:44.783374Z","iopub.status.idle":"2021-11-19T19:33:44.880684Z","shell.execute_reply.started":"2021-11-19T19:33:44.783334Z","shell.execute_reply":"2021-11-19T19:33:44.879980Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"cnn_smdd_results = cnn_smdd.fit_generator(train_data,\n                              steps_per_epoch=30,\n                              epochs=50,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:33:47.659301Z","iopub.execute_input":"2021-11-19T19:33:47.659789Z","iopub.status.idle":"2021-11-19T19:48:30.497782Z","shell.execute_reply.started":"2021-11-19T19:33:47.659752Z","shell.execute_reply":"2021-11-19T19:48:30.496999Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_smdd_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T19:52:15.742461Z","iopub.execute_input":"2021-11-19T19:52:15.742731Z","iopub.status.idle":"2021-11-19T19:52:16.022410Z","shell.execute_reply.started":"2021-11-19T19:52:15.742701Z","shell.execute_reply":"2021-11-19T19:52:16.021756Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"Increasing the number of epochs did seem to decrease loss and the difference in loss between training and testing data.","metadata":{}},{"cell_type":"markdown","source":"**CNN model with early stopping, fewer steps per epoch, more epochs, SGD, normal epsilon, added layers, added Dropout layers**","metadata":{}},{"cell_type":"code","source":"early_stop = [EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss',\n                           save_best_only=True)]","metadata":{"execution":{"iopub.status.busy":"2021-11-19T20:01:26.154701Z","iopub.execute_input":"2021-11-19T20:01:26.154973Z","iopub.status.idle":"2021-11-19T20:01:26.160172Z","shell.execute_reply.started":"2021-11-19T20:01:26.154930Z","shell.execute_reply":"2021-11-19T20:01:26.159242Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# An example of a CNN set up from this GitHub: https://github.com/flatiron-school/DSLE-083021-Phase4-NN-Review/blob/main/Phase4Review-NNs-Text-Images.ipynb\ncnn_esmdd = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_esmdd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn_esmdd.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_esmdd.add(layers.MaxPooling2D((2, 2)))\ncnn_esmdd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_esmdd.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_esmdd.add(layers.MaxPooling2D((2, 2)))\ncnn_esmdd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_esmdd.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_esmdd.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_esmdd.add(layers.Flatten())\ncnn_esmdd.add(layers.Dense(128, activation='relu'))\ncnn_esmdd.add(layers.Dropout(0.25))\ncnn_esmdd.add(layers.Dense(64, activation='relu'))\ncnn_esmdd.add(layers.Dropout(0.25))\ncnn_esmdd.add(layers.Dense(1, activation='sigmoid'))\n\ncnn_esmdd.compile(loss='binary_crossentropy',\n            optimizer= 'sgd',\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T20:01:29.925463Z","iopub.execute_input":"2021-11-19T20:01:29.926390Z","iopub.status.idle":"2021-11-19T20:01:30.022291Z","shell.execute_reply.started":"2021-11-19T20:01:29.926344Z","shell.execute_reply":"2021-11-19T20:01:30.021590Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"cnn_esmdd_results = cnn_esmdd.fit_generator(train_data,\n                              steps_per_epoch=30,\n                              epochs=50,\n                              callbacks=early_stop,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T20:01:44.974803Z","iopub.execute_input":"2021-11-19T20:01:44.975527Z","iopub.status.idle":"2021-11-19T20:07:51.493543Z","shell.execute_reply.started":"2021-11-19T20:01:44.975487Z","shell.execute_reply":"2021-11-19T20:07:51.492840Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"visualize_training_results(cnn_esmdd_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T20:22:04.010097Z","iopub.execute_input":"2021-11-19T20:22:04.010648Z","iopub.status.idle":"2021-11-19T20:22:04.311654Z","shell.execute_reply.started":"2021-11-19T20:22:04.010609Z","shell.execute_reply":"2021-11-19T20:22:04.310997Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"The end result of accuracy and loss for training and testing data is not too different from the other graph; one interesting thing to note about this model is that in epoch 10, there is virutally no difference in loss between training and testing data, and very little in accuracy; this epoch number results in the least overfitting of this model.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}