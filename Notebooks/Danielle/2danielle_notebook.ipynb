{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-18T23:24:36.501486Z","iopub.execute_input":"2021-11-18T23:24:36.501743Z","iopub.status.idle":"2021-11-18T23:24:43.047320Z","shell.execute_reply.started":"2021-11-18T23:24:36.501714Z","shell.execute_reply":"2021-11-18T23:24:43.046644Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Your code here; transform the image files and then load them into Keras as tensors \n# (be sure to perform a train-val-test split)\nimport keras\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Instantiating a generator object and normalizing the RGB values\ntraingen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\ntestgen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\nvalgen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n\ntrain_data = traingen.flow_from_directory(\n    directory='../input/chest-xray-pneumonia/chest_xray/train',\n    target_size=(150, 150),\n    class_mode='binary',\n    batch_size=20,\n    seed=42\n)\n\ntest_data = testgen.flow_from_directory(\n    directory='../input/chest-xray-pneumonia/chest_xray/test',\n    target_size=(150, 150),\n    class_mode='binary',\n    batch_size=20,\n    seed=42\n)\n\nval_data = valgen.flow_from_directory(\n    directory='../input/chest-xray-pneumonia/chest_xray/val',\n    target_size=(150, 150),\n    class_mode='binary',\n    batch_size=20,\n    seed=42\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:24:43.049074Z","iopub.execute_input":"2021-11-18T23:24:43.049311Z","iopub.status.idle":"2021-11-18T23:24:43.474913Z","shell.execute_reply.started":"2021-11-18T23:24:43.049281Z","shell.execute_reply":"2021-11-18T23:24:43.474241Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"input_shape = (150,150,3)\noutput_shape = 2","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:24:43.476288Z","iopub.execute_input":"2021-11-18T23:24:43.476534Z","iopub.status.idle":"2021-11-18T23:24:43.482800Z","shell.execute_reply.started":"2021-11-18T23:24:43.476501Z","shell.execute_reply":"2021-11-18T23:24:43.482018Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Model building using \"add\"\n\ncnn = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\ncnn.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn.add(layers.MaxPooling2D((2, 2)))\ncnn.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn.add(layers.MaxPooling2D((2, 2)))\ncnn.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn.add(layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn.add(layers.Flatten())\ncnn.add(layers.Dense(128, activation='relu'))\ncnn.add(layers.Dense(1, activation='sigmoid'))\n\ncnn.compile(loss='binary_crossentropy',\n            optimizer=\"adam\",\n            metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:24:43.485763Z","iopub.execute_input":"2021-11-18T23:24:43.486357Z","iopub.status.idle":"2021-11-18T23:24:43.607511Z","shell.execute_reply.started":"2021-11-18T23:24:43.486330Z","shell.execute_reply":"2021-11-18T23:24:43.606862Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"cnn_results = cnn.fit_generator(train_data,\n                            steps_per_epoch=10,\n                            epochs=10,\n                            validation_data=(test_data))","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:24:43.608656Z","iopub.execute_input":"2021-11-18T23:24:43.608872Z","iopub.status.idle":"2021-11-18T23:26:25.349858Z","shell.execute_reply.started":"2021-11-18T23:24:43.608841Z","shell.execute_reply":"2021-11-18T23:26:25.349020Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"cnn.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:26:25.351692Z","iopub.execute_input":"2021-11-18T23:26:25.352077Z","iopub.status.idle":"2021-11-18T23:26:25.366069Z","shell.execute_reply.started":"2021-11-18T23:26:25.352031Z","shell.execute_reply":"2021-11-18T23:26:25.365383Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"cnn_results = cnn.fit_generator(train_data,\n                            steps_per_epoch=10,\n                            epochs=10,\n                            validation_data=(test_data))","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:26:25.367345Z","iopub.execute_input":"2021-11-18T23:26:25.367631Z","iopub.status.idle":"2021-11-18T23:28:05.342722Z","shell.execute_reply.started":"2021-11-18T23:26:25.367598Z","shell.execute_reply":"2021-11-18T23:28:05.341771Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Defining a results visualization function\ndef visualize_training_results(history):\n    '''\n    From https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n    \n    Input: keras history object (output from trained model)\n    '''\n    fig, (ax1, ax2) = plt.subplots(2, sharex=True)\n    fig.suptitle('Model Results')\n\n    # summarize history for accuracy\n    ax1.plot(history.history['accuracy'])\n    ax1.plot(history.history['val_accuracy'])\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['train', 'test'], loc='upper left')\n    # summarize history for loss\n    ax2.plot(history.history['loss'])\n    ax2.plot(history.history['val_loss'])\n    ax2.set_ylabel('Loss')\n    ax2.legend(['train', 'test'], loc='upper left')\n    \n    plt.xlabel('Epoch')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:28:05.344229Z","iopub.execute_input":"2021-11-18T23:28:05.344544Z","iopub.status.idle":"2021-11-18T23:28:05.352777Z","shell.execute_reply.started":"2021-11-18T23:28:05.344504Z","shell.execute_reply":"2021-11-18T23:28:05.351795Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Evaluate!\nscore = cnn.evaluate(test_data, verbose=0)\nprint(\"Test loss:\", score[0])\nprint(\"Test accuracy:\", score[1])\n\n# Visualize results\nvisualize_training_results(cnn_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-18T23:28:05.354392Z","iopub.execute_input":"2021-11-18T23:28:05.355237Z","iopub.status.idle":"2021-11-18T23:28:11.326645Z","shell.execute_reply.started":"2021-11-18T23:28:05.355202Z","shell.execute_reply":"2021-11-18T23:28:11.325799Z"},"trusted":true},"execution_count":13,"outputs":[]}]}