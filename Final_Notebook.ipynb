{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2021-11-19T16:05:46.341784Z","iopub.execute_input":"2021-11-19T16:05:46.342191Z","iopub.status.idle":"2021-11-19T16:05:46.347048Z","shell.execute_reply.started":"2021-11-19T16:05:46.342136Z","shell.execute_reply":"2021-11-19T16:05:46.346091Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":"## **Technical Summary**\n\n\nOur modelling process is composed entirely by a series of neural networks. As with most models, there are a whole host of possible hyperparameters to tune and variety of networks to build. We started by building a simple multilayer perceptron (MLP) model with one hidden layer, in order to obtain a baseline model. We decided to use reLu as the activation function for all layers but the output layer, due to its tendency to prevent activation of all the neurons in a layer at a time, which often yields better results. We used the sigmid function as the activator function in the output layer, since this is a binary classification problem. This first simple MLP model had a big overfitting problem and high loss, so in the next couple of model iterations, we decided to add another hidden layer, and then some dropout layers, with the hope that the second layer would help the network pick up on more patterns and reduce overfitting. There was still a significant overfitting and loss problem, so we decided to move on to a new type of neural network: Convolutional Neural Networks (CNNs). CNNs introduce a type of filtering to images, which helps the network to pick up on patterns, such as edges differences, which might be useful in distinguishing between the different classes of images. We tuned various CNN models by using different optimizers (Adam and Stochastic Gradient Descent), trying different numbers of convolution and dense layers, adding dropout layers, implementing early stopping, testing out different learning rates and values for momentum, and adding class weights to account for the class imbalance (there were approximately 2.88 times as many pneumonia x-rays as there were normal x-rays). In the end, a CNN model with three convolution layers, three dense hidden layers, dropout layers, a Stochastic Gradient Descent optimizer with a learning rate of 0.001 and momentum of 0.9, early stopping, and class weights resulted in the best model, with a training and testing accuracy of around 88%.","metadata":{}},{"cell_type":"markdown","source":"## **Business Understanding**\nCyclops Hospital Network (CHN) owns 4 inpatient hospitals and 27 urgent care centers. The 4 inpatient hospitals each have a pediatric emergency room. The 27 urgent care centers are equipped to perform X-ray and CT imaging and diagnosis/treat peditric patients as well. Overall, CHN thus has 31 locations where pediatric patients who potentially have viral or bacterial pneumonia may seek diagnosis and care. Given certain symptoms and the severity of those symptoms, many of those patients will undergo X-ray imaging of the thorax. Given that a radiologist has a maximum of 12 hours to review these images and the initial assessment of the imaging is done by either an emergency room physician or an urgent care practitioner, who may be less accurate in diagnosing pneumonia via imaging, CHN wishes to create a decision support tool (DST) using a neural network in order to check the assessment of the emergency room and urgent care physicians. \n\nThis DST will help to prevent doctors from missing important diagnoses and sending patients home with lack of care. Given the wide range of timescales during which pneumonia can develop, the similarly wide range of severity of symptoms and the specific dillema many pediatric patients experience in verbalizing their symptoms/health status, this DST will protect at-risk patients from being sent home without care to potentially worsen before a radiologist reviews her or his imaging. Additionally, this DST will protect CHN from malpractice suits that could result from this lack of diagnosis and subsequent lack of care.","metadata":{}},{"cell_type":"markdown","source":"## Directory Setup\nThe purpose of this section will demostrate and justify our data preperations steps used on our data. In our preperation we set up generators for our data, and in the generators we also re-scale and re-size the images before they are fed into our model.\n\nDue to the large size of our dataset, we chose to use Kaggle as a place to store our data on the cloud. Our directory setup was structured in the following format: \n```\n├── chest-xray                    <- Top level directory\n│   ├── test                      <- Test set images\n│   │   ├── Normal                <- Normal lung photos      \n│   │   │   └── ...\n│   │   └──  Pneumonia            <- Pneumonia lung photos\n│   │   │   └── ...\n│   ├── train                     <- Training set images\n│   │   ├── Normal                <- Normal lung photos \n│   │   │   └── ...\n│   │   └──  Pneumonia            <- Pneumonia lung photos\n│   │   │   └── ...\n│   ├── val                       <- Training set images\n│   │   ├── Normal                <- Normal lung photos \n│   │   │   └── ...\n│   │   └──  Pneumonia            <- Pneumonia lung photos\n│   │   │   └── ...             \n```\nThis setup allows us to use Kera's Image Data Generator to load our data. We chose to use a generator for 3 reasons:\n- Saving memory and disk space by not downloading the dataset\n- Integrating the preproccesing into our modeling process\n- Easy re-sizing and rescaling of images\nUsing generators also allows more easily reproducable results. Since images fed into our model this way do not have to be preproccessed beforehand.","metadata":{}},{"cell_type":"code","source":"# Import statements\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport keras\nimport seaborn as sns\nfrom tensorflow.keras.optimizers import SGD","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:05:46.348714Z","iopub.execute_input":"2021-11-19T16:05:46.349126Z","iopub.status.idle":"2021-11-19T16:05:46.358467Z","shell.execute_reply.started":"2021-11-19T16:05:46.349087Z","shell.execute_reply":"2021-11-19T16:05:46.357616Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"# Instantiating a generator object and normalizing the RGB values\ntraingen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\ntestgen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\nvalgen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n\n# Creating the generator for the training data\ntrain_data = traingen.flow_from_directory(\n    # Specifying location of training data\n    directory='../input/chest-xray-pneumonia/chest_xray/train',\n    # Re-sizing images to 150x150\n    target_size=(150, 150),\n    # Class mode to binary to recoginize the two directories \"NORMAL\" and \"PNEUMONIA\" as the labels\n    class_mode='binary',\n    batch_size=20,\n    seed=42\n)\n# Creating the generator for the testing data\ntest_data = testgen.flow_from_directory(\n    # Specifying location of testing data\n    directory='../input/chest-xray-pneumonia/chest_xray/test',\n    # Re-sizing images to 150x150\n    target_size=(150, 150),\n    # Class mode to binary to recoginize the two directories \"NORMAL\" and \"PNEUMONIA\" as the labels\n    class_mode='binary',\n    batch_size=20,\n    seed=42\n)\n\n# Setting aside a validation set\nval_data = valgen.flow_from_directory(\n    # Specifying location of testing data\n    directory='../input/chest-xray-pneumonia/chest_xray/val',\n    # Re-sizing images to 150x150\n    target_size=(150, 150),\n    # Class mode to binary to recoginize the two directories \"NORMAL\" and \"PNEUMONIA\" as the labels\n    class_mode='binary',\n    batch_size=20,\n    seed=42\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:05:46.359818Z","iopub.execute_input":"2021-11-19T16:05:46.360136Z","iopub.status.idle":"2021-11-19T16:05:47.377869Z","shell.execute_reply.started":"2021-11-19T16:05:46.360099Z","shell.execute_reply":"2021-11-19T16:05:47.377176Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":"## **Data Understanding**\n- Because we want to train a neural network to help identify whether or not a subject has pneumonia or not based on a chest X-ray, this dataset of 5,232 chest X-rays from children will help us train the network and so that it can be of use to doctors. There are 3,883 pneumonia x-rays and 1,349 normal ones, so there is a class imbalance issue. Additionally, each image is a different size, so it is necessary to standardize the images before modelling. \n- In the context of this data, a false positive would mean that the neural network identifies an x-ray as showing evidence of pneumonia, when it is really a normal x-ray. A false negative would mean that the neural network identifies a pneumonia image as being normal.","metadata":{}},{"cell_type":"code","source":"# Putting class information into a dataframe for easy visualizing\nclasses = pd.DataFrame(train_data.classes)\nvalues = classes.value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:05:47.379073Z","iopub.execute_input":"2021-11-19T16:05:47.379349Z","iopub.status.idle":"2021-11-19T16:05:47.387318Z","shell.execute_reply.started":"2021-11-19T16:05:47.379313Z","shell.execute_reply":"2021-11-19T16:05:47.386576Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# Giving the data better labels for visualization\nclass_dict = {0:'Normal', 1:'Pneumonia'}\nclasses[0] = classes[0].map(class_dict)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:05:47.389919Z","iopub.execute_input":"2021-11-19T16:05:47.390583Z","iopub.status.idle":"2021-11-19T16:05:47.397886Z","shell.execute_reply.started":"2021-11-19T16:05:47.390544Z","shell.execute_reply":"2021-11-19T16:05:47.397266Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"# Looking at the distribution of values between x-rays that show pneumonia and those that don't\ndiag = classes[0].value_counts()\ndiag","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:05:47.399350Z","iopub.execute_input":"2021-11-19T16:05:47.399620Z","iopub.status.idle":"2021-11-19T16:05:47.410894Z","shell.execute_reply.started":"2021-11-19T16:05:47.399588Z","shell.execute_reply":"2021-11-19T16:05:47.409985Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"# Creating a bargraph to visualize the class imbalance\nplt.figure(figsize=(12,8))\nsns.set(font_scale=1.4)\nsns.barplot(diag.index, diag.values)\nplt.ylabel(\"Number of Images\")\nplt.title('Distribution of Chest X-ray Images');","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:05:47.412370Z","iopub.execute_input":"2021-11-19T16:05:47.412635Z","iopub.status.idle":"2021-11-19T16:05:47.651657Z","shell.execute_reply.started":"2021-11-19T16:05:47.412601Z","shell.execute_reply":"2021-11-19T16:05:47.650994Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"markdown","source":"**Visualize Transformation**\n\nWe will visualize the first 10 items in the training data set to check that all transformations to the images were done correctly.","metadata":{}},{"cell_type":"code","source":"# Visualize\ntrain_batch = train_data.next()\nfig, axes = plt.subplots(2, 5, figsize=(16, 8))\n    \nfor i in range(10):\n    # Load image into numpy array and re-scale\n    img = np.array(train_batch[0][i] * 255, dtype='uint8')\n    ax = axes[i // 5, i % 5]\n    ax.imshow(img)\nfig.suptitle('Training Images')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:05:47.652986Z","iopub.execute_input":"2021-11-19T16:05:47.653285Z","iopub.status.idle":"2021-11-19T16:05:49.346585Z","shell.execute_reply.started":"2021-11-19T16:05:47.653249Z","shell.execute_reply":"2021-11-19T16:05:49.342526Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"markdown","source":"## **Multilayer Perceptron Models**\n\nWe will start by setting up a baseline multi-layer perceptron model, because this is the most simple kind of Neural Network. We will iterate off of the results, building adjusted models with the goal of obtaining an improved model each time.","metadata":{}},{"cell_type":"markdown","source":"### **Baseline Multilayer Perceptron Model**","metadata":{}},{"cell_type":"code","source":"# Setting up a baseline MLP\nbaseline = keras.Sequential(\n    [\n        keras.Input(shape=(150,150,3)), \n        keras.layers.Flatten(), \n        keras.layers.Dense(100, activation=\"relu\"),\n        keras.layers.Dense(1, activation=\"sigmoid\"),\n    ])\n\nbaseline.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:05:49.348005Z","iopub.execute_input":"2021-11-19T16:05:49.348493Z","iopub.status.idle":"2021-11-19T16:05:49.378909Z","shell.execute_reply.started":"2021-11-19T16:05:49.348457Z","shell.execute_reply":"2021-11-19T16:05:49.378259Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"# Compiling the baseline MLP\nbaseline.compile(optimizer='adam',\n                      loss='binary_crossentropy',\n                      metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:05:49.380057Z","iopub.execute_input":"2021-11-19T16:05:49.380313Z","iopub.status.idle":"2021-11-19T16:05:49.389531Z","shell.execute_reply.started":"2021-11-19T16:05:49.380280Z","shell.execute_reply":"2021-11-19T16:05:49.388767Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"baseline_results = baseline.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data,)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:05:49.390841Z","iopub.execute_input":"2021-11-19T16:05:49.391098Z","iopub.status.idle":"2021-11-19T16:11:31.477704Z","shell.execute_reply.started":"2021-11-19T16:05:49.391065Z","shell.execute_reply":"2021-11-19T16:11:31.476971Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"# Visualizing results\n# Creating figure with 2 subplots\ndef visualize_results(results):\n    '''Note regarding this function: the term used to refer to the metrics for testing data is \"val\", because this is\n    the term used by the neural network models to refer to the testing data metrics (this can be seen by looking at \n    the data that is printed out after each epoch. The testing data, not the validation data, is what is used after each model\n    iteration to look at extent of overfitting. Unless otherwise specified, when the graphs that result from this \n    function say anything about \"val\" or \"validation,\" it is referring to testing data.\" ) '''\n    \n    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(16, 8))\n    # Geting training history from results\n    history = results.history\n    # Ploting on first subplot\n    ax1.plot(history['loss'])\n    ax1.plot(history['val_loss'])\n    # Labeling \n    ax1.xaxis.set_label('Epochs')\n    ax1.yaxis.set_label('Loss')\n    ax1.legend(['loss', 'val_loss'])\n    # Ploting on second subplot\n    ax2.plot(history['acc'])\n    ax2.plot(history['val_acc'])\n    # Labeling \n    ax1.xaxis.set_label('Epochs')\n    ax1.yaxis.set_label('Accuracy')\n    ax2.legend(['Accuracy', 'Val_acc'])\n    fig.suptitle('Loss and Accuracy of Model')","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:11:31.479218Z","iopub.execute_input":"2021-11-19T16:11:31.479749Z","iopub.status.idle":"2021-11-19T16:11:31.488757Z","shell.execute_reply.started":"2021-11-19T16:11:31.479707Z","shell.execute_reply":"2021-11-19T16:11:31.487840Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"markdown","source":"**Important Note about above function**\n\nThe term used to refer to the metrics for testing data is \"val\", because this is the term used by the neural network models to refer to the testing data metrics (this can be seen by looking at the data that is printed out after each epoch). The testing data, not the validation data, is what is used after each model iteration to look at the extent of overfitting. Unless otherwise specified, when the graphs that result from this function say anything about \"val\" or \"validation,\" it is referring to testing data.","metadata":{}},{"cell_type":"code","source":"def oes_matrix(results):\n    \"\"\"\n    Plots a confusion matrix using the results atrribute of a Keras history object\n  \n    Parameters:\n    results (keras.callbacks.History): \n  \n    Returns:\n    None\n    \"\"\"\n    \n    conf = np.array([[results.history['true_positives'][-1], results.history['false_negatives'][-1]], [results.history['false_positives'][-1], results.history['true_negatives'][-1]]])\n    fig, ax = plt.subplots(figsize=(10, 8))\n    heat = sns.heatmap(conf.astype('int'), annot=True, fmt='g', ax=ax )\n    heat.set_xticklabels(['Pneumonia', 'Normal'], fontsize=15)\n    heat.set_yticklabels(['Pneumonia', 'Normal'], fontsize=15)\n    plt.ylabel('True Label',fontsize=18)\n    plt.xlabel('Predicted Label', fontsize=18)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:11:31.490578Z","iopub.execute_input":"2021-11-19T16:11:31.490842Z","iopub.status.idle":"2021-11-19T16:11:31.504467Z","shell.execute_reply.started":"2021-11-19T16:11:31.490806Z","shell.execute_reply":"2021-11-19T16:11:31.503843Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"visualize_results(baseline_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:11:31.509207Z","iopub.execute_input":"2021-11-19T16:11:31.509726Z","iopub.status.idle":"2021-11-19T16:11:32.304236Z","shell.execute_reply.started":"2021-11-19T16:11:31.509698Z","shell.execute_reply":"2021-11-19T16:11:32.303061Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion**\n\nThis model is overfitting; training accuracy is around 95%, while testing data is at around 80%. Additionally, loss for testing data is oscillating too much. Adding another dense layer might help the model pick up on important patterns in the images.","metadata":{}},{"cell_type":"markdown","source":"### **Adding another layer to the baseline MLP**","metadata":{}},{"cell_type":"code","source":"# Setting up a two layer MLP\ntwo_hidden = keras.Sequential(\n    [\n        keras.Input(shape=(150,150,3)), \n        keras.layers.Flatten(), \n        keras.layers.Dense(100, activation=\"relu\"),\n        keras.layers.Dense(50, activation=\"relu\"),\n        keras.layers.Dense(1, activation=\"sigmoid\"),\n    ])\n\ntwo_hidden.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:11:32.305588Z","iopub.execute_input":"2021-11-19T16:11:32.305917Z","iopub.status.idle":"2021-11-19T16:11:32.347752Z","shell.execute_reply.started":"2021-11-19T16:11:32.305880Z","shell.execute_reply":"2021-11-19T16:11:32.346904Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"# Compiling the two hidden layer MLP\ntwo_hidden.compile(optimizer='adam',\n                      loss='binary_crossentropy',\n                      metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:11:32.349398Z","iopub.execute_input":"2021-11-19T16:11:32.349738Z","iopub.status.idle":"2021-11-19T16:11:32.359247Z","shell.execute_reply.started":"2021-11-19T16:11:32.349638Z","shell.execute_reply":"2021-11-19T16:11:32.358467Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"# Fitting the two hidden layer MLP\ntwo_hidden_results = two_hidden.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:11:32.360703Z","iopub.execute_input":"2021-11-19T16:11:32.361225Z","iopub.status.idle":"2021-11-19T16:17:33.236994Z","shell.execute_reply.started":"2021-11-19T16:11:32.361188Z","shell.execute_reply":"2021-11-19T16:17:33.236305Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"visualize_results(two_hidden_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:17:33.238286Z","iopub.execute_input":"2021-11-19T16:17:33.238537Z","iopub.status.idle":"2021-11-19T16:17:33.732639Z","shell.execute_reply.started":"2021-11-19T16:17:33.238504Z","shell.execute_reply":"2021-11-19T16:17:33.731962Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion**\n\nOnce again, the model is overfit. Training data accuracy is around thirty points higher than testing accuracy. No type of regularization has yet been added, so adding some dropout layers may be improve accuracy and reduce aoverfitting, as this works as a type of regulariation. ","metadata":{}},{"cell_type":"markdown","source":"### **Adding Dropout layers to the two layer MLP**","metadata":{}},{"cell_type":"code","source":"two_hidden_dropout = keras.Sequential(\n    [\n        keras.Input(shape=(150,150,3)), \n        keras.layers.Flatten(), \n        keras.layers.Dense(100, activation=\"relu\"),\n        keras.layers.Dropout(0.25),\n        keras.layers.Dense(50, activation=\"relu\"),\n        keras.layers.Dropout(0.25),\n        keras.layers.Dense(1, activation=\"sigmoid\"),\n    ])\n\ntwo_hidden_dropout.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:17:34.008251Z","iopub.execute_input":"2021-11-19T16:17:34.008734Z","iopub.status.idle":"2021-11-19T16:17:34.050139Z","shell.execute_reply.started":"2021-11-19T16:17:34.008696Z","shell.execute_reply":"2021-11-19T16:17:34.049296Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"# Compiling the two hidden layer dropout MLP\ntwo_hidden_dropout.compile(optimizer='adam',\n                      loss='binary_crossentropy',\n                      metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:17:34.051635Z","iopub.execute_input":"2021-11-19T16:17:34.051887Z","iopub.status.idle":"2021-11-19T16:17:34.061442Z","shell.execute_reply.started":"2021-11-19T16:17:34.051853Z","shell.execute_reply":"2021-11-19T16:17:34.060519Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"# Fitting the two hidden layer dropout MLP\ntwo_hidden_dropout_results = two_hidden_dropout.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:17:34.063019Z","iopub.execute_input":"2021-11-19T16:17:34.063436Z","iopub.status.idle":"2021-11-19T16:23:52.640497Z","shell.execute_reply.started":"2021-11-19T16:17:34.063398Z","shell.execute_reply":"2021-11-19T16:23:52.639736Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"visualize_results(two_hidden_dropout_results)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:23:52.641605Z","iopub.execute_input":"2021-11-19T16:23:52.641842Z","iopub.status.idle":"2021-11-19T16:23:53.121692Z","shell.execute_reply.started":"2021-11-19T16:23:52.641809Z","shell.execute_reply":"2021-11-19T16:23:53.120996Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion**\n\nWhile this model is less overfit than the previous iteration (training data accuracy is about ten percentage points higher than testing accuracy), it is much less accurate than the previous model. Additionally, test accuracy does not improve at all over the epochs. Testing loss is oscillating too frequently and with too great a magnitude. Adding some convolution layers might help to filter the images so as to help the model focus on the most important patterns.","metadata":{}},{"cell_type":"markdown","source":"## **Convolutional Neural Network (CNN) Model Iterations**\n\nThe MLP models we have run so far are a good start, but in order to get a network which really capture all of the detail of the images and can pick up on patterns, we need to run some CNNs.","metadata":{}},{"cell_type":"code","source":"# Create model\ndeep_cnn = keras.Sequential()\n\n# Adding first Conv2D and MaxPool layer, starting small and then growing larger.\ndeep_cnn.add(keras.layers.Conv2D(32, (2, 2), activation='relu', input_shape=(150, 150, 3)))\ndeep_cnn.add(keras.layers.MaxPool2D(2, 2))\n\n# Second layer with 64 filters\ndeep_cnn.add(keras.layers.Conv2D(64, (2, 2), activation='relu'))\ndeep_cnn.add(keras.layers.MaxPool2D(2, 2))\n\n# Third layer with 96 filters\ndeep_cnn.add(keras.layers.Conv2D(96, (2, 2), activation='relu'))\ndeep_cnn.add(keras.layers.MaxPool2D(2, 2))\n# Flatten layers, and add Densley connected layers for prediction\ndeep_cnn.add(keras.layers.Flatten())\n\n# Dense layer with 32 nodes\ndeep_cnn.add(keras.layers.Dense(32, activation='relu'))\n\n# Dense layer with 64 nodes\ndeep_cnn.add(keras.layers.Dense(64, activation='relu'))\n\n# Dense layer with 96 nodes\ndeep_cnn.add(keras.layers.Dense(96, activation='relu'))\n\n# Sigmoid output layer\ndeep_cnn.add(keras.layers.Dense(1, 'sigmoid'))\n\n\n#Compile model\ndeep_cnn.compile(\n    loss='binary_crossentropy',\n    optimizer='sgd',\n    # Adding additonal metrics for better monitoring of training.\n    metrics=['acc', 'Recall', 'Precision']\n    \n)\n\n# Fit Model to Training\ndeep_cnn_results = deep_cnn.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-19T16:23:53.122960Z","iopub.execute_input":"2021-11-19T16:23:53.123685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_results(deep_cnn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oes_matrix(deep_cnn)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion**\n\nI added additional metrics on this model for more insights into the results of the training proccess. As far as performance goes it's definetly an improvement from the last model in terms of testing accuracy.\n\nSome other notes about the model:\n\n- The model is still overfitting\n- The testing accuracy is not conistently improving\n- Testing recall (val_recall in the epochs) is very high, ~97% of true positives were identified correctly. This is good, since we decided that, in context of our buisness problem, false negatives are more costly then false positives.\n- Lets change the optimizer to see if this will improve the overfitting issues.","metadata":{}},{"cell_type":"markdown","source":"### **CNN model with added layers and Adam optimizer**","metadata":{}},{"cell_type":"code","source":"# Set up for this CNN model is from this blog:  https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/\ncnn_adam = keras.Sequential()\n# We defined a variable input_shape earlier, can use that here\ncnn_adam.add(keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(150,150,3)))\ncnn_adam.add(keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\ncnn_adam.add(keras.layers.MaxPooling2D((2, 2)))\ncnn_adam.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_adam.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\ncnn_adam.add(keras.layers.MaxPooling2D((2, 2)))\ncnn_adam.add(keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_adam.add(keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\ncnn_adam.add(keras.layers.MaxPooling2D((2, 2)))\n\n# now, to get the proper output\ncnn_adam.add(keras.layers.Flatten())\ncnn_adam.add(keras.layers.Dense(128, activation='relu'))\ncnn_adam.add(keras.layers.Dense(1, activation='sigmoid'))\n\ncnn_adam.compile(loss='binary_crossentropy',\n            optimizer=\"adam\",\n            metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnn_adam_results = cnn_adam.fit_generator(train_data,\n                              steps_per_epoch=100,\n                              epochs=10,\n                              validation_data=test_data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_results(cnn_adam_results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusions**\n\nThis cnn model requires much improvement. It is overfitting to a larger degree than the previous model (the difference between training and testing data accuracy is around 11 percentage points higher in this model compared to the last).The double convolution layers before pooling may not be beneficial to the model, so the convolution strategy will look more like the previous model in the next iteration.\n\nAdditionally, the keras documentation for adam optimizers has a note discussing that for some types of CNN models, the default value for the hyperparameter epsilon in adam (1e-7) may not be the best; they suggest trying bigger values such as 0.1 or 1. This was attempted in a notebook called \"Brooke Image Classification,\" but it was not beneficial to the ultimate progression of models, so it is not included here.","metadata":{}},{"cell_type":"markdown","source":"## **CNN with Dropout Layers, Early Stopping, and More Training**","metadata":{}},{"cell_type":"code","source":"# Create early stopping object\nearly_stopping = [\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n    keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5')\n]\n\n# Create model\nes_cnn = keras.Sequential()\n\n# Adding first Conv2D and MaxPool layer, starting small and then growing larger.\nes_cnn.add(keras.layers.Conv2D(32, (2, 2), activation='relu', input_shape=(150, 150, 3)))\nes_cnn.add(keras.layers.MaxPool2D(2, 2))\n\n# Second layer with 64 filters\nes_cnn.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\nes_cnn.add(keras.layers.MaxPool2D(3, 3))\n\n# Third layer with 96 filters\nes_cnn.add(keras.layers.Conv2D(96, (5, 5), activation='relu'))\nes_cnn.add(keras.layers.MaxPool2D(5, 5))\n# Flatten layers, and add Densley connected layers for prediction\nes_cnn.add(keras.layers.Flatten())\n\n# Dense layer with 32 nodes with dropout layer\nes_cnn.add(keras.layers.Dense(32, activation='relu'))\nes_cnn.add(keras.layers.Dropout(0.3))\n\n# Dense layer with 64 nodes with dropout layer\nes_cnn.add(keras.layers.Dense(64, activation='relu'))\nes_cnn.add(keras.layers.Dropout(0.3))\n\n# Dense layer with 96 nodes with dropout layer\nes_cnn.add(keras.layers.Dense(96, activation='relu'))\nes_cnn.add(keras.layers.Dropout(0.3))\n# Sigmoid output layer\nes_cnn.add(keras.layers.Dense(1, 'sigmoid'))\n\n#Compile model\nes_cnn.compile(\n    loss='binary_crossentropy',\n    optimizer='sgd',\n    # Adding additonal metrics for better monitoring of training.\n    metrics=['acc', 'Recall', 'Precision']\n    \n)\n\n# Fit Model to Training\nes_cnn_results = es_cnn.fit_generator(train_data,\n                              steps_per_epoch=150,\n                              epochs=25,\n                              validation_data=test_data,\n                              callbacks=early_stopping)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_results(es_cnn_results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oes_matrix(visualize_results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion**\n\nEarly stopping is working as intended, however, I've noticed that the first few epochs always have the same testing accuracy: 0.6250.\n\nThe model may be finding the local minimim instead of the global in these epochs. I'll try to tune the learning rate of my optimizer, and seeeing if that changes anything. I will also try to introduce class weights to the model, as that may help with the problem as well.","metadata":{}},{"cell_type":"markdown","source":"## **Final Model**","metadata":{}},{"cell_type":"code","source":"#### # Create model\nop_cnn = keras.Sequential()\n\n# Adding first Conv2D and MaxPool layer, starting small and then growing larger.\nop_cnn.add(keras.layers.Conv2D(32, (2, 2), activation='relu', input_shape=(150, 150, 3)))\nop_cnn.add(keras.layers.MaxPool2D(2, 2))\n\n# Second layer with 64 filters\nop_cnn.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\nop_cnn.add(keras.layers.MaxPool2D(3, 3))\n\n# Third layer with 96 filters\nop_cnn.add(keras.layers.Conv2D(96, (5, 5), activation='relu'))\nop_cnn.add(keras.layers.MaxPool2D(5, 5))\n# Flatten layers, and add Densley connected layers for prediction\nop_cnn.add(keras.layers.Flatten())\n\n# Dense layer with 32 nodes with dropout layer\nop_cnn.add(keras.layers.Dense(32, activation='relu'))\nop_cnn.add(keras.layers.Dropout(0.3))\n\n# Dense layer with 64 nodes with dropout layer\nop_cnn.add(keras.layers.Dense(64, activation='relu'))\nop_cnn.add(keras.layers.Dropout(0.3))\n\n# Dense layer with 96 nodes with dropout layer\nop_cnn.add(keras.layers.Dense(96, activation='relu'))\nop_cnn.add(keras.layers.Dropout(0.3))\n# Sigmoid output layer\nop_cnn.add(keras.layers.Dense(1, 'sigmoid'))\n\n# Create early stopping object\nop_early_stopping = [\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n    keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5')\n]\n# Create optimizer\noptim = SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n\n# Creating class weights\nweights = {\n    0: 2.88, # NORMAL\n    1: 1.    # PNEM\n}\n#Compile model\nop_cnn.compile(\n    loss='binary_crossentropy',\n    optimizer=optim,\n    # Adding additonal metrics for better monitoring of training.\n    metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives']\n    \n)\n\n# Fit Model to Training\nop_cnn_results = op_cnn.fit_generator(train_data,\n                              class_weight=weights,\n                              steps_per_epoch=50,\n                              epochs=100,\n                              validation_data=test_data,\n                              callbacks=op_early_stopping)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_results(op_cnn_results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oes_matrix(op_cnn_results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion**\n\nThe early stopping worked great this time, and the changes to the optimizer, as well as adding class weights,has had a positive impact on the model. Both training and testing accuracy is now sitting around ~88%, so the model is not overfit. Additionally, the testing loss (32%) is lower than the training loss (48%).","metadata":{}},{"cell_type":"markdown","source":"### **Testing the Final Model with the validation data**","metadata":{}},{"cell_type":"code","source":"#### # Create model\nop_cnn_val = keras.Sequential()\n\n# Adding first Conv2D and MaxPool layer, starting small and then growing larger.\nop_cnn_val.add(keras.layers.Conv2D(32, (2, 2), activation='relu', input_shape=(150, 150, 3)))\nop_cnn_val.add(keras.layers.MaxPool2D(2, 2))\n\n# Second layer with 64 filters\nop_cnn_val.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\nop_cnn_val.add(keras.layers.MaxPool2D(3, 3))\n\n# Third layer with 96 filters\nop_cnn_val.add(keras.layers.Conv2D(96, (5, 5), activation='relu'))\nop_cnn_val.add(keras.layers.MaxPool2D(5, 5))\n# Flatten layers, and add Densley connected layers for prediction\nop_cnn_val.add(keras.layers.Flatten())\n\n# Dense layer with 32 nodes with dropout layer\nop_cnn_val.add(keras.layers.Dense(32, activation='relu'))\nop_cnn_val.add(keras.layers.Dropout(0.3))\n\n# Dense layer with 64 nodes with dropout layer\nop_cnn_val.add(keras.layers.Dense(64, activation='relu'))\nop_cnn_val.add(keras.layers.Dropout(0.3))\n\n# Dense layer with 96 nodes with dropout layer\nop_cnn_val.add(keras.layers.Dense(96, activation='relu'))\nop_cnn_val.add(keras.layers.Dropout(0.3))\n# Sigmoid output layer\nop_cnn_val.add(keras.layers.Dense(1, 'sigmoid'))\n\n# Create early stopping object\nop_early_stopping = [\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n    keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5')\n]\n# Create optimizer\noptim = SGD(learning_rate=0.001, momentum=0.9, nesterov=True)\n\n# Creating class weights\nweights = {\n    0: 2.88, # NORMAL\n    1: 1.    # PNEM\n}\n\n\n# Compile the model\nop_cnn_val.compile(\n    loss='binary_crossentropy',\n    optimizer=optim,\n    # Adding additonal metrics for better monitoring of training.\n    metrics=['acc', 'Recall', 'Precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives']\n    \n)\n\n# Fit Model to Training\nop_cnn_val_results = op_cnn_val.fit_generator(train_data,\n                              class_weight=weights,\n                              steps_per_epoch=50,\n                              epochs=100,\n                              validation_data=val_data,\n                              callbacks=op_early_stopping)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_results(op_cnn_val_results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusions**\n\nTesting the final model out on the validation data (data the model has not yet seen) resulted in overfitting and more loss than when we used it on testing data. This may be because the validation set is so small, composed only of 16 images.","metadata":{}},{"cell_type":"markdown","source":"## **Overall Conclusions**","metadata":{}},{"cell_type":"markdown","source":"Throughout this process of neural network iterations, a series of different neural network models were created, and many different hyperparameters were tuned. In the end, a CNN model with three convolution layers, three dense hidden layers, dropout layers, a Stochastic Gradient Descent optimizer with a learning rate of 0.001 and momentum of 0.9, early stopping, and class weights resulted in the best model, with a training and testing accuracy at around 88%.  Additionally, the model has a recall of around 92%,and a precision of 89%, meaning that it does a good job at minimizing false negatives and false positives. What this translates to is that the model will make correct diagnoses around 90% of the time. This CNN model will do a good job with assisting ER physicians as a decision support tool with diagnosing pneumonia. There are also some further steps we would like to take in order to evaluate the efficacy of the CNN decision support tool, such as calculating the \"case save rate\" (number of cases wherein the ordering physician would have interpreted the xray incorrectly, released the patient and delayed care, BUT didn’t because the CNN decision support tool informed the physician that s/he may have been incorrect, resulting in immediate care) of the model. We would also like to estimate the monetary savings due to decrease in care delay and lawsuits. ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}